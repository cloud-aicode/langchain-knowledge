<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>æœ€ä½³å®è·µ - LangChain 1.0 çŸ¥è¯†ç‚¹</title>
    <link rel="stylesheet" href="../assets/css/style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
</head>
<body class="chapter-best-practices">
    <button class="theme-toggle">ğŸŒ“</button>
    <button class="mobile-menu-btn" onclick="toggleSidebar()">â˜°</button>

    <div class="app-container">
        <nav class="sidebar">
            <div class="sidebar-header">
                <h1><a href="../index.html" style="color: white; text-decoration: none;">LangChain 1.0</a></h1>
                <p style="color: rgba(255,255,255,0.6); font-size: 0.9rem; margin-top: 5px;">çŸ¥è¯†ç‚¹</p>
            </div>
            <div class="sidebar-nav"></div>
        </nav>

        <main class="main-content">
            <div class="content">
                <h1>æœ€ä½³å®è·µ (Best Practices)</h1>
                <p class="subtitle">ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æŒ‡å—</p>

                <h2>ç”Ÿäº§éƒ¨ç½²æ¸…å•</h2>

                <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin: 20px 0;">
                    <div style="padding: 20px; background: rgba(16, 185, 129, 0.1); border-radius: 10px;">
                        <div style="font-size: 1.5rem;">âœ…</div>
                        <div style="font-weight: 600; margin-top: 10px;">é”™è¯¯å¤„ç†</div>
                        <div style="font-size: 0.9rem; margin-top: 5px; color: rgba(0,0,0,0.6);">try-except + é‡è¯•æœºåˆ¶</div>
                    </div>
                    <div style="padding: 20px; background: rgba(245, 158, 11, 0.1); border-radius: 10px;">
                        <div style="font-size: 1.5rem;">âš¡</div>
                        <div style="font-weight: 600; margin-top: 10px;">æ€§èƒ½ä¼˜åŒ–</div>
                        <div style="font-size: 0.9rem; margin-top: 5px; color: rgba(0,0,0,0.6);">æ‰¹å¤„ç†ã€ç¼“å­˜ã€æµå¼</div>
                    </div>
                    <div style="padding: 20px; background: rgba(239, 68, 68, 0.1); border-radius: 10px;">
                        <div style="font-size: 1.5rem;">ğŸ”’</div>
                        <div style="font-weight: 600; margin-top: 10px;">å®‰å…¨æ€§</div>
                        <div style="font-size: 0.9rem; margin-top: 5px; color: rgba(0,0,0,0.6);">è¾“å…¥éªŒè¯ã€æç¤ºæ³¨å…¥é˜²æŠ¤</div>
                    </div>
                    <div style="padding: 20px; background: rgba(59, 130, 246, 0.1); border-radius: 10px;">
                        <div style="font-size: 1.5rem;">ğŸ“Š</div>
                        <div style="font-weight: 600; margin-top: 10px;">ç›‘æ§æ—¥å¿—</div>
                        <div style="font-size: 0.9rem; margin-top: 5px; color: rgba(0,0,0,0.6);">è¿½è¸ªã€æŒ‡æ ‡ã€å‘Šè­¦</div>
                    </div>
                </div>

                <h2>init_chat_model() ç»Ÿä¸€åˆå§‹åŒ–ï¼ˆv1.0 æ–°ç‰¹æ€§ï¼‰</h2>

                <p><code>init_chat_model()</code> æ˜¯ LangChain 1.0 çš„ç»Ÿä¸€æ¨¡å‹åˆå§‹åŒ–æ¥å£ï¼Œæ”¯æŒå¤šæä¾›å•†ï¼š</p>

                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">python</span>
                        <button class="copy-btn">å¤åˆ¶</button>
                    </div>
                    <pre><code class="language-python">from langchain.chat_models import init_chat_model

# æ–¹å¼ä¸€ï¼šä»ç¯å¢ƒå˜é‡è‡ªåŠ¨é€‰æ‹©æä¾›å•†
llm = init_chat_model(
    model="gpt-4o",
    temperature=0.7
)

# æ–¹å¼äºŒï¼šæŒ‡å®šæä¾›å•†
llm = init_chat_model(
    model="claude-3-5-sonnet-20241022",
    model_provider="anthropic",
    temperature=0.5,
    max_tokens=1000
)

# æ–¹å¼ä¸‰ï¼šè¿è¡Œæ—¶åŠ¨æ€é…ç½®
llm = init_chat_model(
    model="gpt-4o",
    temperature=0,
    configurable_fields={
        "temperature": 0.7,
        "max_tokens": 1000,
        "model": "gpt-4o-mini"  # è¿è¡Œæ—¶åˆ‡æ¢æ¨¡å‹
    }
)

# æ”¯æŒçš„æä¾›å•†ï¼š
# - openai: GPT-4, GPT-4o, GPT-4o-mini
# - anthropic: Claude 3.5 Sonnet, Claude 3 Opus
# - google: Gemini Pro, Gemini Flash
# - mistralai: Mistral Large, Mixtral</code></pre>
                </div>

                <pre class="mermaid">graph TD
    A[init_chat_model] --> B{æ¨¡å‹é€‰æ‹©}
    B -->|ç¯å¢ƒå˜é‡| C[è‡ªåŠ¨æ£€æµ‹æä¾›å•†]
    B -->|æŒ‡å®š| D[Anthropic/OpenAI/Google]
    C --> E[è¿”å› LLM å®ä¾‹]
    D --> E
    E --> F[ç»Ÿä¸€æ¥å£è°ƒç”¨]</code></pre>

                <h2>å¯é…ç½®æ¨¡å‹ï¼ˆconfigurable_fieldsï¼‰</h2>

                <p>å…è®¸åœ¨è¿è¡Œæ—¶åŠ¨æ€é…ç½®æ¨¡å‹å‚æ•°ï¼š</p>

                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">python</span>
                        <button class="copy-btn">å¤åˆ¶</button>
                    </div>
                    <pre><code class="language-python">from langchain_openai import ChatOpenAI
from langchain_core.runnables import ConfigurableField

# åˆ›å»ºå¯é…ç½®æ¨¡å‹
llm = ChatOpenAI(model="gpt-4o").configurable_fields(
    temperature=ConfigurableField(
        id="llm_temperature",
        name="LLM Temperature",
        description="æ§åˆ¶è¾“å‡ºçš„éšæœºæ€§"
    ),
    model=ConfigurableField(
        id="llm_model",
        name="LLM Model",
        description="ä½¿ç”¨çš„æ¨¡å‹åç§°"
    ),
    max_tokens=ConfigurableField(
        id="llm_max_tokens",
        name="Max Tokens",
        description="æœ€å¤§è¾“å‡º tokens"
    )
)

# ä½¿ç”¨æ—¶é…ç½®
result = llm.invoke(
    "è®²ä¸€ä¸ªç®€çŸ­çš„æ•…äº‹",
    config={"configurable": {
        "llm_temperature": 0.9,
        "llm_model": "gpt-4o-mini",
        "llm_max_tokens": 100
    }}
)</code></pre>
                </div>

                <h2>é€Ÿç‡é™åˆ¶å™¨ï¼ˆInMemoryRateLimiterï¼‰</h2>

                <p>é˜²æ­¢ API è°ƒç”¨è¶…è¿‡é€Ÿç‡é™åˆ¶ï¼š</p>

                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">python</span>
                        <button class="copy-btn">å¤åˆ¶</button>
                    </div>
                    <pre><code class="language-python">from langchain_core.rate_limiters import InMemoryRateLimiter
from langchain_openai import ChatOpenAI

# åˆ›å»ºé€Ÿç‡é™åˆ¶å™¨ï¼ˆä»¤ç‰Œæ¡¶ç®—æ³•ï¼‰
rate_limiter = InMemoryRateLimiter(
    requests_per_second=0.1,     # æ¯ 10 ç§’ 1 ä¸ªè¯·æ±‚
    check_every_n_seconds=0.1,    # æ¯ 100ms æ£€æŸ¥ä¸€æ¬¡
    max_bucket_size=10            # æœ€å¤§çªå‘è¯·æ±‚æ•°
)

# åº”ç”¨åˆ°æ¨¡å‹
llm = ChatOpenAI(
    model="gpt-4o",
    rate_limiter=rate_limiter
)

# æ‰¹é‡è°ƒç”¨æ—¶ä¼šè‡ªåŠ¨é™åˆ¶
inputs = ["é—®é¢˜1", "é—®é¢˜2", "é—®é¢˜3"]
results = llm.batch(inputs)</code></pre>
                </div>

                <pre class="mermaid">graph LR
    A[è¯·æ±‚] --> B[é€Ÿç‡é™åˆ¶å™¨]
    B --> C{ä»¤ç‰Œæ¡¶}
    C -->|æœ‰ä»¤ç‰Œ| D[å‘é€è¯·æ±‚]
    C -->|æ— ä»¤ç‰Œ| E[ç­‰å¾…]
    E --> C
    D --> F[å¤„ç†å“åº”]</code></pre>

                <h3>å¤šæä¾›å•†é€Ÿç‡é™åˆ¶</h3>

                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">python</span>
                        <button class="copy-btn">å¤åˆ¶</button>
                    </div>
                    <pre><code class="language-python">from langchain_core.rate_limiters import InMemoryRateLimiter
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic

# ä¸ºä¸åŒæä¾›å•†é…ç½®ä¸åŒé™åˆ¶
openai_limiter = InMemoryRateLimiter(requests_per_second=2)
anthropic_limiter = InMemoryRateLimiter(requests_per_second=1)

openai_llm = ChatOpenAI(
    model="gpt-4o",
    rate_limiter=openai_limiter
)

anthropic_llm = ChatAnthropic(
    model="claude-3-5-sonnet-20241022",
    rate_limiter=anthropic_limiter
)</code></pre>
                </div>

                <h2>ä»£ç†é…ç½®</h2>

                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">python</span>
                        <button class="copy-btn">å¤åˆ¶</button>
                    </div>
                    <pre><code class="language-python">import os
from langchain_openai import ChatOpenAI
import httpx

# æ–¹å¼ä¸€ï¼šç¯å¢ƒå˜é‡
os.environ["HTTP_PROXY"] = "http://proxy.example.com:8080"
os.environ["HTTPS_PROXY"] = "http://proxy.example.com:8080"

llm = ChatOpenAI(model="gpt-4o")

# æ–¹å¼äºŒï¼šç›´æ¥é…ç½®ï¼ˆæ¨èï¼‰
llm = ChatOpenAI(
    model="gpt-4o",
    http_client=httpx.AsyncClient(
        proxies="http://proxy.example.com:8080",
        timeout=30.0
    )
)

# æ–¹å¼ä¸‰ï¼šSOCKS ä»£ç†
import httpx_socks

llm = ChatOpenAI(
    model="gpt-4o",
    http_client=httpx.AsyncClient(
        proxy=httpx_socks.Proxy(
            proxy_url="socks5://127.0.0.1:1080"
        )
    )
)</code></pre>
                </div>

                <h2>è‡ªå®šä¹‰å›è°ƒå¤„ç†å™¨</h2>

                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">python</span>
                        <button class="copy-btn">å¤åˆ¶</button>
                    </div>
                    <pre><code class="language-python">from langchain_core.callbacks import BaseCallbackHandler
from langchain_core.outputs import LLMResult
from typing import Any, Dict, List

class TokenCounterCallback(BaseCallbackHandler):
    """è‡ªå®šä¹‰ Token è®¡æ•°å›è°ƒ"""

    def __init__(self):
        self.prompt_tokens = 0
        self.completion_tokens = 0
        self.total_tokens = 0

    def on_llm_start(self, prompts: List[str], **kwargs) -> None:
        """LLM å¼€å§‹æ—¶è°ƒç”¨"""
        print(f"å¼€å§‹å¤„ç†ï¼Œæç¤ºè¯é•¿åº¦: {len(prompts[0])}")

    def on_llm_end(self, response: LLMResult, **kwargs) -> None:
        """LLM ç»“æŸæ—¶è°ƒç”¨"""
        for generation in response.generations:
            for output in generation:
                if hasattr(output, 'generation_info'):
                    info = output.generation_info or {}
                    self.prompt_tokens += info.get('prompt_tokens', 0)
                    self.completion_tokens += info.get('completion_tokens', 0)
                    self.total_tokens += info.get('total_tokens', 0)

        print(f"æœ¬æ¬¡è°ƒç”¨ - è¾“å…¥: {self.prompt_tokens}, è¾“å‡º: {self.completion_tokens}")

    def get_stats(self) -> Dict[str, int]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "prompt_tokens": self.prompt_tokens,
            "completion_tokens": self.completion_tokens,
            "total_tokens": self.total_tokens
        }

# ä½¿ç”¨å›è°ƒ
counter = TokenCounterCallback()

llm = ChatOpenAI(
    model="gpt-4o",
    callbacks=[counter]
)

result = llm.invoke("å†™ä¸€é¦–è¯—")
print(counter.get_stats())</code></pre>
                </div>

                <h2>æµå¼å›è°ƒ</h2>

                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">python</span>
                        <button class="copy-btn">å¤åˆ¶</button>
                    </div>
                    <pre><code class="language-python">from langchain_core.callbacks import BaseCallbackHandler
from langchain_core.messages import BaseMessage

class StreamingCallback(BaseCallbackHandler):
    """æµå¼è¾“å‡ºå›è°ƒ"""

    def __init__(self):
        self.tokens = []

    def on_llm_new_token(self, token: str, **kwargs) -> None:
        """æ¯ä¸ªæ–° token æ—¶è°ƒç”¨"""
        self.tokens.append(token)
        print(token, end="", flush=True)

    def get_full_response(self) -> str:
        """è·å–å®Œæ•´å“åº”"""
        return "".join(self.tokens)

# ä½¿ç”¨æµå¼å›è°ƒ
streaming = StreamingCallback()

llm = ChatOpenAI(
    model="gpt-4o",
    streaming=True,
    callbacks=[streaming]
)

result = llm.invoke("è®²ä¸€ä¸ªçŸ­æ•…äº‹")
print(f"\nå®Œæ•´å“åº”é•¿åº¦: {len(streaming.get_full_response())}")</code></pre>
                </div>

                <pre class="mermaid">sequenceDiagram
    participant U as ç”¨æˆ·
    participant LLM as LLM
    participant CB as Callback
    participant S as ç»Ÿè®¡æœåŠ¡

    U->>LLM: è°ƒç”¨ invoke
    LLM->>CB: on_llm_start
    LLM->>CB: on_llm_new_token (æµå¼)
    LLM->>CB: on_llm_end
    CB->>S: è®°å½•ç»Ÿè®¡
    LLM-->>U: è¿”å›ç»“æœ</code></pre>

                <h2>æˆæœ¬é¢„ç®—æ§åˆ¶</h2>

                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">python</span>
                        <button class="copy-btn">å¤åˆ¶</button>
                    </div>
                    <pre><code class="language-python">from langchain_openai import ChatOpenAI
from langchain.callbacks import get_openai_callback

class BudgetExceededError(Exception):
    """è¶…å‡ºé¢„ç®—å¼‚å¸¸"""
    pass

class BudgetControlCallback:
    """é¢„ç®—æ§åˆ¶å›è°ƒ"""

    PRICES = {
        "gpt-4o": {"input": 0.005, "output": 0.015},    # æ¯ 1K tokens
        "gpt-4o-mini": {"input": 0.00015, "output": 0.0006}
    }

    def __init__(self, model: str, budget: float):
        self.model = model
        self.budget = budget
        self.spent = 0.0

    def check_budget(self, cb) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¶…å‡ºé¢„ç®—"""
        if self.spent >= self.budget:
            raise BudgetExceededError(
                f"å·²è¶…å‡ºé¢„ç®—: ${self.spent:.4f} / ${self.budget:.4f}"
            )
        return True

    def update_cost(self, cb) -> None:
        """æ›´æ–°æˆæœ¬"""
        prices = self.PRICES.get(self.model, {"input": 0, "output": 0})
        input_cost = cb.prompt_tokens / 1000 * prices["input"]
        output_cost = cb.completion_tokens / 1000 * prices["output"]
        self.spent += input_cost + output_cost

# ä½¿ç”¨é¢„ç®—æ§åˆ¶
budget_controller = BudgetControlCallback("gpt-4o", budget=1.0)
llm = ChatOpenAI(model="gpt-4o")

try:
    with get_openai_callback() as cb:
        for i in range(10):
            budget_controller.check_budget(cb)
            result = llm.invoke(f"é—®é¢˜ {i}")
            budget_controller.update_cost(cb)
            print(f"å·²æ¶ˆè´¹: ${budget_controller.spent:.4f}")
except BudgetExceededError as e:
    print(e)</code></pre>
                </div>

                <h2>é”™è¯¯å¤„ç†</h2>

                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">python</span>
                        <button class="copy-btn">å¤åˆ¶</button>
                    </div>
                    <pre><code class="language-python">from langchain_core.runnables import RunnableRetryWithMessage, RunnableWithFallbacks
from langchain_openai import ChatOpenAI

# å¸¦é‡è¯•çš„é“¾
llm = ChatOpenAI(model="gpt-4o")

retry_chain = RunnableRetryWithMessage(
    llm,
    max_retries=3,
    retry_error_message="ç”Ÿæˆå¤±è´¥ï¼Œæ­£åœ¨é‡è¯•..."
)

# ä¼˜é›…é™çº§
primary = ChatOpenAI(model="gpt-4o")
fallback = ChatOpenAI(model="gpt-4o-mini")

chain_with_fallback = RunnableWithFallbacks(
    primary,
    fallbacks=[fallback]
)

# ä½¿ç”¨
try:
    result = retry_chain.invoke("å†™ä¸€é¦–è¯—")
except Exception as e:
    result = chain_with_fallback.invoke("å†™ä¸€é¦–è¯—")</code></pre>
                </div>

                <h2>æ€§èƒ½ä¼˜åŒ–</h2>

                <h3>æ‰¹é‡å¤„ç†</h3>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">python</span>
                        <button class="copy-btn">å¤åˆ¶</button>
                    </div>
                    <pre><code class="language-python">from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

llm = ChatOpenAI(model="gpt-4o")
prompt = ChatPromptTemplate.from_template("ç¿»è¯‘æˆè‹±æ–‡ï¼š{text}")
chain = prompt | llm

# æ‰¹é‡è°ƒç”¨
inputs = [
    {"text": "ä½ å¥½"},
    {"text": "ä¸–ç•Œ"},
    {"text": "LangChain"}
]

# æ–¹å¼ä¸€ï¼šbatch()
results = chain.batch(inputs)

# æ–¹å¼äºŒï¼šå¹¶å‘æ‰¹å¤„ç†
async def abatch_chain():
    return await chain.abatch(inputs)

import asyncio
results = asyncio.run(abatch_chain())</code></pre>
                </div>

                <h3>ç¼“å­˜</h3>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">python</span>
                        <button class="copy-btn">å¤åˆ¶</button>
                    </div>
                    <pre><code class="language-python">from langchain_core.cache import InMemoryCache, RedisCache
from langchain_openai import ChatOpenAI
from langchain_core.globals import set_llm_cache

# å¯ç”¨å†…å­˜ç¼“å­˜
set_llm_cache(InMemoryCache())

# æˆ–ä½¿ç”¨ Redis ç¼“å­˜
set_llm_cache(RedisCache(
    redis_url="redis://localhost:6379/0"
))

llm = ChatOpenAI(model="gpt-4o")

# ç¬¬ä¸€æ¬¡è°ƒç”¨ä¼šæ‰§è¡Œ
result1 = llm.invoke("ä»€ä¹ˆæ˜¯ Pythonï¼Ÿ")

# ç›¸åŒè¾“å…¥ä¼šè¿”å›ç¼“å­˜ç»“æœ
result2 = llm.invoke("ä»€ä¹ˆæ˜¯ Pythonï¼Ÿ")
print(result1 == result2)  # True</code></pre>
                </div>

                <h2>å®‰å…¨æ€§</h2>

                <div class="warning" data-label="å®‰å…¨è­¦å‘Š">
                    <strong>æç¤ºæ³¨å…¥</strong>ï¼šæ¶æ„ç”¨æˆ·å¯èƒ½é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„è¾“å…¥æ¥æ“çºµæ¨¡å‹è¡Œä¸ºã€‚å§‹ç»ˆéªŒè¯å’Œæ¸…ç†ç”¨æˆ·è¾“å…¥ã€‚
                </div>

                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">python</span>
                        <button class="copy-btn">å¤åˆ¶</button>
                    </div>
                    <pre><code class="language-python">import re

def validate_input(user_input: str) -> str:
    """éªŒè¯å’Œæ¸…ç†ç”¨æˆ·è¾“å…¥"""
    # ç§»é™¤å±é™©å­—ç¬¦
    cleaned = re.sub(r'[<>{}]', '', user_input)

    # é™åˆ¶é•¿åº¦
    if len(cleaned) > 1000:
        cleaned = cleaned[:1000]

    # æ£€æµ‹æ³¨å…¥æ¨¡å¼
    injection_patterns = [
        r'å¿½ç•¥.*æŒ‡ä»¤',
        r'forget.*instructions',
        r'override.*system',
    ]
    for pattern in injection_patterns:
        if re.search(pattern, cleaned, re.IGNORECASE):
            raise ValueError("æ£€æµ‹åˆ°æ½œåœ¨çš„æ³¨å…¥æ”»å‡»")

    return cleaned

def create_safe_prompt(user_input: str) -> str:
    """åˆ›å»ºå®‰å…¨çš„æç¤º"""
    cleaned = validate_input(user_input)
    return f"è¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š{cleaned}"</code></pre>
                </div>

                <h2>ç›‘æ§ä¸å¯è§‚æµ‹æ€§</h2>

                <pre class="mermaid">graph TD
    A[åº”ç”¨] --> B[LangSmith è¿½è¸ª]
    A --> C[æ—¥å¿—è®°å½•]
    A --> D[æŒ‡æ ‡ç›‘æ§]
    B --> E[è°ƒç”¨é“¾å¯è§†åŒ–]
    B --> F[æ€§èƒ½åˆ†æ]
    C --> G[é”™è¯¯æ—¥å¿—]
    D --> H[Token ä½¿ç”¨]
    D --> I[å»¶è¿Ÿç›‘æ§]</code></pre>

                <h2>v0.1 â†’ v1.0 è¿ç§»æŒ‡å—</h2>

                <table class="comparison-table">
                    <tr>
                        <th>v0.1</th>
                        <th>v1.0</th>
                        <th>è¿ç§»æ–¹å¼</th>
                    </tr>
                    <tr>
                        <td><code>initialize_agent</code></td>
                        <td><code>create_agent</code></td>
                        <td>é‡å†™ Agent åˆ›å»ºé€»è¾‘</td>
                    </tr>
                    <tr>
                        <td><code>LLMChain</code></td>
                        <td><code>|</code> (LCEL)</td>
                        <td>ä½¿ç”¨ <code>|</code> é‡å†™é“¾</td>
                    </tr>
                    <tr>
                        <td><code>ConversationChain</code></td>
                        <td><code>MessagesPlaceholder</code></td>
                        <td>ä½¿ç”¨æ–°æç¤ºæ¨¡æ¿</td>
                    </tr>
                    <tr>
                        <td><code>Tool.from_function</code></td>
                        <td><code>@tool</code></td>
                        <td>ä½¿ç”¨è£…é¥°å™¨é‡å†™</td>
                    </tr>
                    <tr>
                        <td><code>langchain.llms</code></td>
                        <td><code>langchain_openai</code></td>
                        <td>æ›´æ–°å¯¼å…¥è·¯å¾„</td>
                    </tr>
                </table>

                <div class="tip" data-label="è¿ç§»æç¤º">
                    ä½¿ç”¨ <code>langchain-classic</code> åŒ…å¯ä»¥æš‚æ—¶ä¿æŒå…¼å®¹ï¼Œä½†å»ºè®®å°½å¿«è¿ç§»åˆ° v1.0 æ–° APIã€‚
                </div>

                <nav class="chapter-nav">
                    <a href="09-retrieval.html" class="prev">â† RAGæ£€ç´¢</a>
                    <a href="../index.html" class="next">è¿”å›ç›®å½• â†’</a>
                </nav>

                <div class="exercise-section">
                    <h3>âœï¸ ç»ƒä¹ é¢˜</h3>

                    <div class="question">
                        <div class="question-title">
                            <span class="question-type">é€‰æ‹©é¢˜</span>
                            1. init_chat_model() çš„ä¸»è¦ä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ
                        </div>
                        <div class="options">
                            <div class="option" onclick="this.classList.toggle('selected')">A. æ›´å¿«çš„æ¨ç†é€Ÿåº¦</div>
                            <div class="option" onclick="this.classList.toggle('selected')">B. æ›´ä½çš„æˆæœ¬</div>
                            <div class="option correct-option onclick="this.classList.toggle('selected')">C. æä¾›å•†æ— å…³çš„ç»Ÿä¸€åˆå§‹åŒ–æ¥å£</div>
                            <div class="option" onclick="this.classList.toggle('selected')">D. è‡ªåŠ¨ä¼˜åŒ–æç¤ºè¯</div>
                        </div>
                    </div>

                    <div class="question">
                        <div class="question-title">
                            <span class="question-type">é€‰æ‹©é¢˜</span>
                            2. InMemoryRateLimiter ä½¿ç”¨ä»€ä¹ˆç®—æ³•æ§åˆ¶é€Ÿç‡ï¼Ÿ
                        </div>
                        <div class="options">
                            <div class="option" onclick="this.classList.toggle('selected')">A. æ¼æ¡¶ç®—æ³•</div>
                            <div class="option correct-option onclick="this.classList.toggle('selected')">B. ä»¤ç‰Œæ¡¶ç®—æ³•</div>
                            <div class="option" onclick="this.classList.toggle('selected')">C. å›ºå®šçª—å£è®¡æ•°</div>
                            <div class="option" onclick="this.classList.toggle('selected')">D. æ»‘åŠ¨çª—å£è®¡æ•°</div>
                        </div>
                    </div>

                    <div class="question">
                        <div class="question-title">
                            <span class="question-type">é€‰æ‹©é¢˜</span>
                            3. configurable_fields å…è®¸åšä»€ä¹ˆï¼Ÿ
                        </div>
                        <div class="options">
                            <div class="option" onclick="this.classList.toggle('selected')">A. ç¼–è¯‘æ—¶é…ç½®æ¨¡å‹</div>
                            <div class="option correct-option onclick="this.classList.toggle('selected')">B. è¿è¡Œæ—¶åŠ¨æ€é…ç½®æ¨¡å‹å‚æ•°</div>
                            <div class="option" onclick="this.classList.toggle('selected')">C. è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ¨¡å‹</div>
                            <div class="option" onclick="this.classList.toggle('selected')">D. é™åˆ¶æ¨¡å‹è¾“å‡ºé•¿åº¦</div>
                        </div>
                    </div>

                    <div class="question">
                        <div class="question-title">
                            <span class="question-type">ä»£ç å¡«ç©º</span>
                            4. è¡¥å…¨ä»¥ä¸‹å¯é…ç½®æ¨¡å‹çš„ä»£ç 
                        </div>
                        <div class="code-block">
                            <div class="code-header">
                                <span class="code-language">python</span>
                            </div>
                            <pre><code class="language-python">result = llm.invoke(
    "å†™ä¸€é¦–è¯—",
    config={"______": {
        "llm_temperature": 0.9,
        "llm_model": "gpt-4o-mini"
    }}
)</code></pre>
                        </div>
                        <details style="margin-top: 10px;">
                            <summary style="cursor: pointer; color: var(--primary-color);">æŸ¥çœ‹ç­”æ¡ˆ</summary>
                            <div style="margin-top: 10px; padding: 10px; background: rgba(16, 185, 129, 0.1); border-radius: 5px;">
                                <code>configurable</code>
                            </div>
                        </details>
                    </div>

                    <div class="question">
                        <div class="question-title">
                            <span class="question-type">é€‰æ‹©é¢˜</span>
                            5. ä»£ç†é…ç½®åº”è¯¥åœ¨å“ªé‡Œè®¾ç½®æœ€åˆé€‚ï¼Ÿ
                        </div>
                        <div class="options">
                            <div class="option" onclick="this.classList.toggle('selected')">A. åœ¨æ“ä½œç³»ç»Ÿç½‘ç»œè®¾ç½®ä¸­</div>
                            <div class="option" onclick="this.classList.toggle('selected')">B. åªèƒ½ä½¿ç”¨ç¯å¢ƒå˜é‡</div>
                            <div class="option correct-option onclick="this.classList.toggle('selected')">C. ç¯å¢ƒå˜é‡æˆ– http_client å‚æ•°</div>
                            <div class="option" onclick="this.classList.toggle('selected')">D. ä¸æ”¯æŒä»£ç†é…ç½®</div>
                        </div>
                    </div>

                    <div class="question">
                        <div class="question-title">
                            <span class="question-type">ç¼–ç¨‹é¢˜</span>
                            6. å®ç°ä¸€ä¸ªå®Œæ•´çš„é¢„ç®—æ§åˆ¶ç³»ç»Ÿï¼ŒåŒ…å«é€Ÿç‡é™åˆ¶å’Œæˆæœ¬è¿½è¸ª
                        </div>
                        <details style="margin-top: 10px;">
                            <summary style="cursor: pointer; color: var(--primary-color);">æŸ¥çœ‹å‚è€ƒç­”æ¡ˆ</summary>
                            <div class="code-block" style="margin-top: 10px;">
                                <div class="code-header">
                                    <span class="code-language">python</span>
                                    <button class="copy-btn">å¤åˆ¶</button>
                                </div>
                                <pre><code class="language-python">from langchain_openai import ChatOpenAI
from langchain.callbacks import get_openai_callback
from langchain_core.rate_limiters import InMemoryRateLimiter

class BudgetControlledLLM:
    def __init__(self, model: str, budget: float, rate_limit: float):
        self.model = model
        self.budget = budget
        self.spent = 0.0
        self.rate_limiter = InMemoryRateLimiter(
            requests_per_second=rate_limit
        )
        self.llm = ChatOpenAI(
            model=model,
            rate_limiter=self.rate_limiter
        )
        self.prices = {
            "gpt-4o": {"input": 0.005, "output": 0.015},
            "gpt-4o-mini": {"input": 0.00015, "output": 0.0006}
        }

    def invoke(self, prompt: str):
        """å¸¦é¢„ç®—æ§åˆ¶çš„è°ƒç”¨"""
        # æ£€æŸ¥é¢„ç®—
        if self.spent >= self.budget:
            raise Exception(f"é¢„ç®—å·²ç”¨å°½: ${self.spent:.4f}/${self.budget:.4f}")

        # è°ƒç”¨å¹¶è¿½è¸ªæˆæœ¬
        with get_openai_callback() as cb:
            result = self.llm.invoke(prompt)

            # æ›´æ–°èŠ±è´¹
            prices = self.prices.get(self.model, {"input": 0, "output": 0})
            cost = (cb.prompt_tokens / 1000 * prices["input"] +
                   cb.completion_tokens / 1000 * prices["output"])
            self.spent += cost

            print(f"æœ¬æ¬¡æˆæœ¬: ${cost:.6f}, æ€»èŠ±è´¹: ${self.spent:.4f}/${self.budget:.4f}")
            return result

# ä½¿ç”¨
llm = BudgetControlledLLM("gpt-4o", budget=1.0, rate_limit=0.5)

for i in range(10):
    try:
        result = llm.invoke(f"é—®é¢˜ {i}")
    except Exception as e:
        print(e)
        break</code></pre>
                            </div>
                        </details>
                    </div>

                    <div class="question">
                        <div class="question-title">
                            <span class="question-type">åœºæ™¯é¢˜</span>
                            7. ä½ éœ€è¦ä¸ºä¸€ä¸ªä¼ä¸šè®¾è®¡ç”Ÿäº§ç¯å¢ƒé…ç½®ï¼Œè¦æ±‚ï¼šé«˜å¯ç”¨ã€æˆæœ¬å¯æ§ã€å®‰å…¨åˆè§„
                        </div>
                        <details style="margin-top: 10px;">
                            <summary style="cursor: pointer; color: var(--primary-color);">æŸ¥çœ‹å‚è€ƒæ–¹æ¡ˆ</summary>
                            <div style="margin-top: 15px; padding: 15px; background: rgba(59, 130, 246, 0.1); border-radius: 10px;">
                                <strong>æ–¹æ¡ˆè¦ç‚¹ï¼š</strong>
                                <ul>
                                    <li><strong>é«˜å¯ç”¨</strong>ï¼šé…ç½® fallback åˆ°å¤‡ç”¨æ¨¡å‹å’Œæä¾›å•†ï¼Œå®æ–½é‡è¯•æœºåˆ¶</li>
                                    <li><strong>é€Ÿç‡é™åˆ¶</strong>ï¼šä½¿ç”¨ InMemoryRateLimiter æ§åˆ¶ API è°ƒç”¨é¢‘ç‡</li>
                                    <li><strong>æˆæœ¬æ§åˆ¶</strong>ï¼šè®¾ç½®é¢„ç®—ä¸Šé™ï¼Œä½¿ç”¨ get_openai_callback è¿½è¸ªæˆæœ¬</li>
                                    <li><strong>è¾“å…¥éªŒè¯</strong>ï¼šä¸¥æ ¼éªŒè¯ç”¨æˆ·è¾“å…¥ï¼Œé˜²æ­¢æç¤ºæ³¨å…¥æ”»å‡»</li>
                                    <li><strong>ä»£ç†é…ç½®</strong>ï¼šé€šè¿‡ä»£ç†æœåŠ¡å™¨è®¿é—®å¤–éƒ¨ API</li>
                                    <li><strong>ç›‘æ§</strong>ï¼šä½¿ç”¨è‡ªå®šä¹‰å›è°ƒè®°å½• Token ä½¿ç”¨å’Œè°ƒç”¨é“¾è·¯</li>
                                    <li><strong>ç¼“å­˜</strong>ï¼šä½¿ç”¨ Redis ç¼“å­˜å¸¸è§æŸ¥è¯¢ï¼Œå‡å°‘ API è°ƒç”¨</li>
                                </ul>
                            </div>
                        </details>
                    </div>

                    <div class="question">
                        <div class="question-title">
                            <span class="question-type">é€‰æ‹©é¢˜</span>
                            8. å“ªä¸ªå›è°ƒæ–¹æ³•åœ¨æ¯ä¸ªæ–° token æ—¶è¢«è°ƒç”¨ï¼Ÿ
                        </div>
                        <div class="options">
                            <div class="option" onclick="this.classList.toggle('selected')">A. on_llm_start</div>
                            <div class="option" onclick="this.classList.toggle('selected')">B. on_llm_end</div>
                            <div class="option correct-option onclick="this.classList.toggle('selected')">C. on_llm_new_token</div>
                            <div class="option" onclick="this.classList.toggle('selected')">D. on_chain_start</div>
                        </div>
                    </div>
                </div>
            </div>
        </main>
    </div>

    <script src="../assets/js/main.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
</body>
</html>
