<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>é“¾å¼è°ƒç”¨ - LangChain 1.0 çŸ¥è¯†ç‚¹</title>
    <link rel="stylesheet" href="assets/css/style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
</head>
<body class="chapter-chains">
    <button class="theme-toggle">ğŸŒ“</button>
    <button class="mobile-menu-btn" onclick="toggleSidebar()">â˜°</button>

    <div class="app-container">
        <nav class="sidebar">
            <div class="sidebar-header">
                <h1>LangChain 1.0</h1>
                <p style="color: rgba(255,255,255,0.6); font-size: 0.9rem; margin-top: 5px;">çŸ¥è¯†ç‚¹</p>
            </div>
            <div class="sidebar-nav"></div>
        </nav>

        <main class="main-content">
            <div class="content">
                <h1>é“¾å¼è°ƒç”¨ (Chains)</h1>
                <p class="subtitle">ä½¿ç”¨ LCEL æ„å»ºå¤æ‚çš„å·¥ä½œæµ</p>

                <h2>ä»€ä¹ˆæ˜¯ LCELï¼Ÿ</h2>
                <p><strong>LCEL (LangChain Expression Language)</strong> æ˜¯ LangChain 1.0 çš„å£°æ˜å¼é“¾å¼è¯­æ³•ï¼Œä½¿ç”¨ <code>|</code> æ“ä½œç¬¦ç»„åˆç»„ä»¶ã€‚</p>

                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">python</span>
                        <button class="copy-btn">å¤åˆ¶</button>
                    </div>
                    <pre><code class="language-python"># LCEL åŸºæœ¬è¯­æ³•
chain = prompt | model | parser

# ç­‰ä»·äºä¼ ç»Ÿå†™æ³•ï¼š
# chain = prompt | model | parser</code></pre>
                </div>

                <h2>Runnable æ¥å£</h2>
                <p>æ‰€æœ‰ LCEL ç»„ä»¶éƒ½å®ç° <code>Runnable</code> æ¥å£ï¼Œæä¾›ç»Ÿä¸€çš„æ–¹æ³•ï¼š</p>

                <table class="comparison-table">
                    <tr>
                        <th>æ–¹æ³•</th>
                        <th>è¯´æ˜</th>
                    </tr>
                    <tr>
                        <td><code>stream()</code></td>
                        <td>æµå¼è¾“å‡º</td>
                    </tr>
                    <tr>
                        <td><code>invoke()</code></td>
                        <td>åŒæ­¥è°ƒç”¨</td>
                    </tr>
                    <tr>
                        <td><code>ainvoke()</code></td>
                        <td>å¼‚æ­¥è°ƒç”¨</td>
                    </tr>
                    <tr>
                        <td><code>batch()</code></td>
                        <td>æ‰¹é‡å¤„ç†</td>
                    </tr>
                    <tr>
                        <td><code>abatch()</code></td>
                        <td>å¼‚æ­¥æ‰¹é‡å¤„ç†</td>
                    </tr>
                    <tr>
                        <td><code>map()</code></td>
                        <td>å¹¶è¡Œæ˜ å°„</td>
                    </tr>
                </table>

                <h2>åŸºç¡€é“¾æ„å»º</h2>

                <h3>ç®€å•é“¾</h3>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">python</span>
                        <button class="copy-btn">å¤åˆ¶</button>
                    </div>
                    <pre><code class="language-python">from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI

# åˆ›å»ºç»„ä»¶
prompt = ChatPromptTemplate.from_template("è®²ä¸ªå…³äº{topic}çš„ç¬‘è¯")
llm = ChatOpenAI(model="gpt-4o")
parser = StrOutputParser()

# ç”¨ | ç»„åˆæˆé“¾
joke_chain = prompt | llm | parser

# è°ƒç”¨
result = joke_chain.invoke({"topic": "ç¨‹åºå‘˜"})
print(result)</code></pre>
                </div>

                <h3>å¹¶è¡Œæ‰§è¡Œ</h3>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">python</span>
                        <button class="copy-btn">å¤åˆ¶</button>
                    </div>
                    <pre><code class="language-python">from langchain_core.runnables import RunnableParallel

# å¹¶è¡Œé“¾ï¼šåŒæ—¶æ‰§è¡Œå¤šä¸ªæ“ä½œ
chain = RunnableParallel(
    joke=prompt | llm | parser,
    count=prompt | llm | StrOutputParser() | len
)

# åŒæ—¶è·å–ç¬‘è¯å’Œå­—æ•°
result = chain.invoke({"topic": "AI"})
print(result)
# è¾“å‡º: {'joke': '...', 'count': 150}</code></pre>
                </div>

                <h3>è·¯ç”±é“¾</h3>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">python</span>
                        <button class="copy-btn">å¤åˆ¶</button>
                    </div>
                    <pre><code class="language-python">from langchain_core.runnables import RunnableLambda
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

# å®šä¹‰ä¸åŒçš„å¤„ç†å‡½æ•°
def handle_code(input):
    return "è¿™æ˜¯ä»£ç é—®é¢˜"

def handle_general(input):
    return "è¿™æ˜¯ä¸€èˆ¬é—®é¢˜"

# åˆ›å»ºè·¯ç”±
from langchain_core.runnables import RunnableBranch

branch = RunnableBranch(
    (lambda x: "ä»£ç " in x, RunnableLambda(handle_code)),
    (lambda x: True, RunnableLambda(handle_general))
)

# ä½¿ç”¨è·¯ç”±
result = branch.invoke("æˆ‘çš„ä»£ç æœ‰é—®é¢˜")
print(result)  # "è¿™æ˜¯ä»£ç é—®é¢˜"</code></pre>
                </div>

                <h2>å¤æ‚é“¾å¼ç»„åˆ</h2>

                <h3>é¡ºåºæ‰§è¡Œ</h3>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">python</span>
                        <button class="copy-btn">å¤åˆ¶</button>
                    </div>
                    <pre><code class="language-python">from langchain_core.runnables import RunnablePassthrough

# å¤æ‚é“¾ï¼šå…ˆæ€»ç»“ï¼Œå†ç¿»è¯‘ï¼Œå†æ ¼å¼åŒ–
summary_prompt = ChatPromptTemplate.from_template("æ€»ç»“ä»¥ä¸‹å†…å®¹ï¼š\n{content}")
translate_prompt = ChatPromptTemplate.from_template("ç¿»è¯‘æˆè‹±æ–‡ï¼š\n{summary}")
format_prompt = ChatPromptTemplate.from_template("æ ¼å¼åŒ–ä¸ºåˆ—è¡¨ï¼š\n{translation}")

llm = ChatOpenAI(model="gpt-4o")

chain = (
    {"content": lambda x: x["content"]}
    | summary_prompt | llm
    | {"summary": lambda x: x.content}
    | translate_prompt | llm
    | {"translation": lambda x: x.content}
    | format_prompt | llm
)</code></pre>
                </div>

                <h3>ä¸­é—´æ­¥éª¤è®¿é—®</h3>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">python</span>
                        <button class="copy-btn">å¤åˆ¶</button>
                    </div>
                    <pre><code class="language-python">from langchain_core.runnables import RunnablePassthrough

# RunnablePassthrough ä¼ é€’è¾“å…¥ï¼ŒåŒæ—¶æ·»åŠ æ–°å­—æ®µ
chain = {
    "original": RunnablePassthrough(),  # ä¿ç•™åŸå§‹è¾“å…¥
    "processed": prompt | llm | StrOutputParser()  # å¤„ç†åçš„è¾“å‡º
}

result = chain.invoke({"query": "Python æ˜¯ä»€ä¹ˆ"})
# è¾“å‡º: {'original': {'query': '...'}, 'processed': '...'}</code></pre>
                </div>

                <h2>é”™è¯¯å¤„ç†</h2>

                <h3>é‡è¯•æœºåˆ¶</h3>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">python</span>
                        <button class="copy-btn">å¤åˆ¶</button>
                    </div>
                    <pre><code class="language-python">from langchain_core.runnables import RunnableRetryWithMessage
from langchain_openai import ChatOpenAI

# åˆ›å»ºå¸¦é‡è¯•çš„é“¾
llm = ChatOpenAI(model="gpt-4o")

retry_chain = RunnableRetryWithMessage(
    llm,
    max_retries=3,
    retry_error_message="è¯·é‡æ–°ç”Ÿæˆ"
)

result = retry_chain.invoke("è®²ä¸ªç¬‘è¯")</code></pre>
                </div>

                <h3>å›é€€ç­–ç•¥</h3>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">python</span>
                        <button class="copy-btn">å¤åˆ¶</button>
                    </div>
                    <pre><code class="language-python">from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic

# ä¸»æ¨¡å‹å’Œå›é€€æ¨¡å‹
primary = ChatOpenAI(model="gpt-4o")
fallback = ChatAnthropic(model="claude-sonnet-4-5-20250514")

# åˆ›å»ºå›é€€é“¾
from langchain_core.runnables import RunnableWithFallbacks

chain_with_fallback = RunnableWithFallbacks(
    primary,
    fallbacks=[fallback]
)

# ä¸»æ¨¡å‹å¤±è´¥æ—¶è‡ªåŠ¨ä½¿ç”¨å›é€€
result = chain_with_fallback.invoke("Hello")</code></pre>
                </div>

                <h2>LCEL æµç¨‹å›¾</h2>

                <pre class="mermaid">graph TD
    A[è¾“å…¥] --> B[PromptTemplate]
    B --> C[ChatModel]
    C --> D[OutputParser]
    D --> E[è¾“å‡º]

    C -.->|é”™è¯¯| F[Fallback Model]
    F --> D</code></pre>

                <h2>åŠ¨æ€é“¾æ„å»º</h2>

                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">python</span>
                        <button class="copy-btn">å¤åˆ¶</button>
                    </div>
                    <pre><code class="language-python">from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

# åŠ¨æ€é€‰æ‹©æ¨¡å‹
def create_chain(model_name: str):
    if model_name == "openai":
        llm = ChatOpenAI(model="gpt-4o")
    elif model_name == "anthropic":
        from langchain_anthropic import ChatAnthropic
        llm = ChatAnthropic(model="claude-sonnet-4-5-20250514")
    else:
        raise ValueError(f"Unknown model: {model_name}")

    prompt = ChatPromptTemplate.from_template("å›ç­”ï¼š{question}")
    return prompt | llm

# ä½¿ç”¨
chain = create_chain("openai")
result = chain.invoke({"question": "ä»€ä¹ˆæ˜¯ LCELï¼Ÿ"})</code></pre>
                </div>

                <nav class="chapter-nav">
                    <a href="03-prompts.html" class="prev">â† æç¤ºå·¥ç¨‹</a>
                    <a href="05-agents.html" class="next">æ™ºèƒ½ä½“ â†’</a>
                </nav>

                <div class="exercise-section">
                    <h3>âœï¸ ç»ƒä¹ é¢˜</h3>

                    <div class="question">
                        <div class="question-title">
                            <span class="question-type">é€‰æ‹©é¢˜</span>
                            1. LCEL ä¸­çš„ <code>|</code> æ“ä½œç¬¦çš„ä½œç”¨æ˜¯ï¼Ÿ
                        </div>
                        <div class="options">
                            <div class="option" onclick="this.classList.toggle('selected')">A. é€»è¾‘æˆ–è¿ç®—</div>
                            <div class="option correct-option onclick="this.classList.toggle('selected')">B. é“¾å¼ç»„åˆç»„ä»¶</div>
                            <div class="option" onclick="this.classList.toggle('selected')">C. ä½è¿ç®—</div>
                            <div class="option" onclick="this.classList.toggle('selected')">D. å­—ç¬¦ä¸²æ‹¼æ¥</div>
                        </div>
                    </div>

                    <div class="question">
                        <div class="question-title">
                            <span class="question-type">ç¼–ç¨‹é¢˜</span>
                            2. åˆ›å»ºä¸€ä¸ªé“¾ï¼šè¾“å…¥é—®é¢˜ â†’ è·å–ç­”æ¡ˆ â†’ ç¿»è¯‘æˆè‹±æ–‡ â†’ è®¡ç®—å­—æ•°
                        </div>
                        <details style="margin-top: 10px;">
                            <summary style="cursor: pointer; color: var(--primary-color);">æŸ¥çœ‹å‚è€ƒç­”æ¡ˆ</summary>
                            <div class="code-block" style="margin-top: 10px;">
                                <div class="code-header">
                                    <span class="code-language">python</span>
                                    <button class="copy-btn">å¤åˆ¶</button>
                                </div>
                                <pre><code class="language-python">from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-4o")

# é—®é¢˜ -> ç­”æ¡ˆ
qa_prompt = ChatPromptTemplate.from_template("å›ç­”ï¼š{question}")
qa_chain = qa_prompt | llm

# ç¿»è¯‘
translate_prompt = ChatPromptTemplate.from_template("ç¿»è¯‘æˆè‹±æ–‡ï¼š{text}")
translate_chain = translate_prompt | llm

# ç»„åˆå®Œæ•´é“¾
chain = (
    qa_chain
    | {"answer": lambda x: x.content}
    | (lambda x: translate_chain.invoke({"text": x["answer"]}))
    | {"translation": lambda x: x.content, "count": lambda x: len(x.content)}
)

result = chain.invoke({"question": "ä»€ä¹ˆæ˜¯ Pythonï¼Ÿ"})
print(result)  # {'translation': '...', 'count': ...}</code></pre>
                            </div>
                        </details>
                    </div>
                </div>
            </div>
        </main>
    </div>

    <script src="assets/js/main.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
</body>
</html>