<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>è®°å¿†ç®¡ç† API - LangChain 1.0</title>
    <link rel="stylesheet" href="../assets/css/style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
</head>
<body class="chapter-api-memory">
    <button class="theme-toggle">ğŸŒ“</button>
    <button class="mobile-menu-btn" onclick="toggleSidebar()">â˜°</button>

    <div class="app-container">
        <nav class="sidebar">
            <div class="sidebar-header">
                <h1>LangChain 1.0</h1>
                <p style="color: rgba(255,255,255,0.6); font-size: 0.9rem; margin-top: 5px;">API å‚è€ƒ</p>
            </div>
            <div class="sidebar-nav"></div>
        </nav>

        <main class="main-content">
            <div class="content">
                <h1>è®°å¿†ç®¡ç† API</h1>
                <p class="subtitle">Memory ä¸å¯¹è¯å†å²</p>

                <div class="api-nav">
                    <a href="#overview" class="api-nav-link">æ¦‚è¿°</a>
                    <a href="#legacy" class="api-nav-link">ä¼ ç»Ÿ Memory</a>
                    <a href="#new" class="api-nav-link">æ–°å¼ RunnableWithMessageHistory</a>
                    <a href="#examples" class="api-nav-link">ç¤ºä¾‹</a>
                </div>

                <h2 id="overview">æ¦‚è¿°</h2>
                <p>è®°å¿†ç®¡ç†ç”¨äºåœ¨å¯¹è¯ä¸­ä¿æŒä¸Šä¸‹æ–‡ã€‚LangChain æä¾›äº†ä¼ ç»Ÿ Memory ç±»å’Œæ–°çš„ RunnableWithMessageHistory åŒ…è£…å™¨ã€‚</p>

                <pre class="mermaid">graph TD
                    A[Memory] --> B[ConversationBufferMemory]
                    A --> C[ConversationSummaryMemory]
                    A --> D[ConversationBufferWindowMemory]
                    A --> E[ConversationKGMemory]
                    A --> F[ConversationSummaryBufferMemory]

    G[RunnableWithMessageHistory] --> H[æ–°å¼è®°å¿†]
    H --> I[get_session_history]

    style A fill:#e1f5fe
    style G fill:#c8e6c9</code></pre>

                <h2 id="legacy">ä¼ ç»Ÿ Memory ç±»</h2>

                <div class="api-section">
                    <h3 class="api-title">BaseMemory</h3>
                    <p class="api-description">ä¼ ç»Ÿ Memory åŸºç±»ï¼ˆå·²å¼ƒç”¨ï¼‰ã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">from langchain.memory import BaseMemory

class BaseMemory(Serializable, ABC):
    """Memory åŸºç±»"""

    @property
    @abstractmethod
    def memory_variables(self) -> List[str]:
        """è¿”å›å†…å­˜å˜é‡ååˆ—è¡¨"""

    @abstractmethod
    def load_memory_variables(
        self,
        inputs: Dict[str, Any],
    ) -> Dict[str, Any]:
        """
        åŠ è½½å†…å­˜å˜é‡

        Args:
            inputs: å½“å‰è¾“å…¥

        Returns:
            å†…å­˜å˜é‡å­—å…¸
        """

    @abstractmethod
    def save_context(
        self,
        inputs: Dict[str, Any],
        outputs: Dict[str, Any],
    ) -> None:
        """
        ä¿å­˜ä¸Šä¸‹æ–‡

        Args:
            inputs: è¾“å…¥
            outputs: è¾“å‡º
        """

    def clear(self) -> None:
        """æ¸…ç©ºå†…å­˜"""</code></pre>
                    </div>
                </div>

                <div class="api-section">
                    <h3 class="api-title">ConversationBufferMemory</h3>
                    <p class="api-description">ç¼“å†²æ‰€æœ‰å¯¹è¯å†å²ã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">from langchain.memory import ConversationBufferMemory

class ConversationBufferMemory(BaseMemory):
    """å¯¹è¯ç¼“å†²å†…å­˜"""

    human_prefix: str = "Human"
    """ç”¨æˆ·æ¶ˆæ¯å‰ç¼€"""

    ai_prefix: str = "AI"
    """AI æ¶ˆæ¯å‰ç¼€"""

    return_messages: bool = False
    """æ˜¯å¦è¿”å›æ¶ˆæ¯å¯¹è±¡è€Œéå­—ç¬¦ä¸²"""

    input_key: str = "input"
    output_key: str = "output"

    def __init__(
        self,
        return_messages: bool = False,
        human_prefix: str = "Human",
        ai_prefix: str = "AI",
        chat_memory: Optional[BaseChatMessageHistory] = None,
    ):
        """
        åˆå§‹åŒ–

        Args:
            return_messages: æ˜¯å¦è¿”å›æ¶ˆæ¯å¯¹è±¡
            human_prefix: ç”¨æˆ·å‰ç¼€
            ai_prefix: AI å‰ç¼€
            chat_memory: èŠå¤©å†å²å­˜å‚¨
        """</code></pre>
                    </div>

                    <h4>ä½¿ç”¨ç¤ºä¾‹</h4>
                    <div class="code-block">
                        <div class="code-header">
                            <span class="code-language">python</span>
                            <button class="copy-btn">å¤åˆ¶</button>
                        </div>
                        <pre><code class="language-python">from langchain.memory import ConversationBufferMemory
from langchain_openai import OpenAI

# åˆ›å»º Memory
memory = ConversationBufferMemory(
    return_messages=True,
    human_prefix="User",
    ai_prefix="Assistant"
)

# ä¿å­˜ä¸Šä¸‹æ–‡
memory.save_context(
    inputs={"input": "ä½ å¥½"},
    outputs={"output": "ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„ï¼Ÿ"}
)

# åŠ è½½å†…å­˜
memory_variables = memory.load_memory_variables({})
print(memory_variables["history"])

# æŸ¥çœ‹æ¶ˆæ¯
for msg in memory.chat_memory.messages:
    print(f"{msg.type}: {msg.content}")</code></pre>
                    </div>
                </div>

                <div class="api-section">
                    <h3 class="api-title">ConversationSummaryMemory</h3>
                    <p class="api-description">æ€»ç»“å¯¹è¯å†å²ã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">from langchain.memory import ConversationSummaryMemory

class ConversationSummaryMemory(BaseMemory):
    """å¯¹è¯æ€»ç»“å†…å­˜"""

    llm: BaseLanguageModel
    """ç”¨äºç”Ÿæˆæ€»ç»“çš„ LLM"""

    prompt: BasePromptTemplate = DEFAULT_SUMMARY_PROMPT
    """æ€»ç»“æç¤ºæ¨¡æ¿"""

    summary: str = ""
    """å½“å‰æ€»ç»“"""

    def __init__(
        self,
        llm: BaseLanguageModel,
        prompt: Optional[BasePromptTemplate] = None,
        return_messages: bool = False,
    ):
        """
        åˆå§‹åŒ–

        Args:
            llm: è¯­è¨€æ¨¡å‹
            prompt: æ€»ç»“æç¤º
            return_messages: æ˜¯å¦è¿”å›æ¶ˆæ¯å¯¹è±¡
        """</code></pre>
                    </div>

                    <h4>ä½¿ç”¨ç¤ºä¾‹</h4>
                    <div class="code-block">
                        <div class="code-header">
                            <span class="code-language">python</span>
                            <button class="copy-btn">å¤åˆ¶</button>
                        </div>
                        <pre><code class="language-python">from langchain.memory import ConversationSummaryMemory
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-4o", temperature=0)

memory = ConversationSummaryMemory(
    llm=llm,
    return_messages=False
)

# ä¿å­˜å¯¹è¯ï¼ˆè‡ªåŠ¨æ€»ç»“ï¼‰
memory.save_context(
    inputs={"input": "æˆ‘æ˜¯ Alice"},
    outputs={"output": "ä½ å¥½ Aliceï¼"}
)

memory.save_context(
    inputs={"input": "æˆ‘å–œæ¬¢ç¼–ç¨‹"},
    outputs={"output": "é‚£å¾ˆæ£’ï¼"}
)

# è·å–æ€»ç»“
summary = memory.load_memory_variables({})["summary"]
print(summary)
# "Alice ä»‹ç»äº†è‡ªå·±ï¼Œå¹¶è¡¨ç¤ºå–œæ¬¢ç¼–ç¨‹ã€‚"</code></pre>
                    </div>
                </div>

                <div class="api-section">
                    <h3 class="api-title">ConversationBufferWindowMemory</h3>
                    <p class="api-description">åªä¿ç•™æœ€è¿‘ k è½®å¯¹è¯ã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">from langchain.memory import ConversationBufferWindowMemory

class ConversationBufferWindowMemory(BaseMemory):
    """çª—å£ç¼“å†²å†…å­˜"""

    k: int = 5
    """ä¿ç•™çš„è½®æ•°"""

    memory_key: str = "history"

    def __init__(
        self,
        k: int = 5,
        return_messages: bool = False,
    ):
        """
        åˆå§‹åŒ–

        Args:
            k: ä¿ç•™çš„å¯¹è¯è½®æ•°
            return_messages: æ˜¯å¦è¿”å›æ¶ˆæ¯å¯¹è±¡
        """</code></pre>
                    </div>

                    <h4>ä½¿ç”¨ç¤ºä¾‹</h4>
                    <div class="code-block">
                        <div class="code-header">
                            <span class="code-language">python</span>
                            <button class="copy-btn">å¤åˆ¶</button>
                        </div>
                        <pre><code class="language-python">from langchain.memory import ConversationBufferWindowMemory

memory = ConversationBufferWindowMemory(
    k=2,  # åªä¿ç•™æœ€è¿‘ 2 è½®
    return_messages=True
)

# æ·»åŠ å¤šè½®å¯¹è¯
for i in range(5):
    memory.save_context(
        inputs={"input": f"æ¶ˆæ¯ {i*2+1}"},
        outputs={"output": f"å›å¤ {i*2+2}"}
    )

# åªä¿ç•™æœ€è¿‘ 2 è½®
history = memory.load_memory_variables({})["history"]
print(f"æ¶ˆæ¯æ•°: {len(history)}")  # 4 (2è½® x 2æ¡)</code></pre>
                    </div>
                </div>

                <div class="api-section">
                    <h3 class="api-title">ConversationSummaryBufferMemory</h3>
                    <p class="api-description">ç»“åˆæ€»ç»“å’Œç¼“å†²çš„å†…å­˜ã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">from langchain.memory import ConversationSummaryBufferMemory

class ConversationSummaryBufferMemory(BaseMemory):
    """æ€»ç»“ç¼“å†²å†…å­˜"""

    max_token_limit: int = 2000
    """æœ€å¤§ token æ•°"""

    llm: BaseLanguageModel

    def __init__(
        self,
        llm: BaseLanguageModel,
        max_token_limit: int = 2000,
        return_messages: bool = False,
    ):
        """
        åˆå§‹åŒ–

        Args:
            llm: è¯­è¨€æ¨¡å‹
            max_token_limit: æœ€å¤§ token æ•°
            return_messages: æ˜¯å¦è¿”å›æ¶ˆæ¯å¯¹è±¡
        """</code></pre>
                    </div>

                    <h4>ä½¿ç”¨ç¤ºä¾‹</h4>
                    <div class="code-block">
                        <div class="code-header">
                            <span class="code-language">python</span>
                            <button class="copy-btn">å¤åˆ¶</button>
                        </div>
                        <pre><code class="language-python">from langchain.memory import ConversationSummaryBufferMemory
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-4o")

memory = ConversationSummaryBufferMemory(
    llm=llm,
    max_token_limit=100,
    return_messages=True
)

# æ·»åŠ å¯¹è¯ï¼ˆè¶…è¿‡é™åˆ¶ä¼šè‡ªåŠ¨æ€»ç»“ï¼‰
memory.save_context(
    inputs={"input": "é•¿å¯¹è¯å†…å®¹..."},
    outputs={"output": "é•¿å›å¤å†…å®¹..."}
)</code></pre>
                    </div>
                </div>

                <h2 id="new">æ–°å¼ RunnableWithMessageHistory</h2>

                <div class="api-section">
                    <h3 class="api-title">RunnableWithMessageHistory</h3>
                    <p class="api-description">æ¨èçš„æ–°å¼è®°å¿†ç®¡ç†æ–¹å¼ã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">from langchain_core.runnables.history import RunnableWithMessageHistory

class RunnableWithMessageHistory(Runnable[Input, Output]):
    """å¸¦æ¶ˆæ¯å†å²çš„ Runnable"""

    runnable: Runnable[Input, Output]
    """åº•å±‚ Runnable"""

    get_session_history: Callable[[str], BaseChatMessageHistory]
    """è·å–å†å²è®°å½•çš„å‡½æ•°"""

    input_messages_key: str = "input"
    """è¾“å…¥æ¶ˆæ¯åœ¨è¾“å…¥ä¸­çš„é”®å"""

    history_messages_key: str = "history"
    """å†å²æ¶ˆæ¯åœ¨è¾“å…¥ä¸­çš„é”®å"""

    def __init__(
        self,
        runnable: Runnable[Input, Output],
        get_session_history: Callable[[str], BaseChatMessageHistory],
        *,
        input_messages_key: str = "input",
        history_messages_key: str = "history",
    ):
        """
        åˆå§‹åŒ–

        Args:
            runnable: åº•å±‚ Runnableï¼ˆå¦‚ prompt | llmï¼‰
            get_session_history: è·å–å†å²çš„å‡½æ•°
                æ¥æ”¶ session_idï¼Œè¿”å› BaseChatMessageHistory
            input_messages_key: è¾“å…¥æ¶ˆæ¯çš„é”®å
            history_messages_key: å†å²æ¶ˆæ¯çš„é”®å
        """</code></pre>
                    </div>

                    <h4>ä½¿ç”¨ç¤ºä¾‹</h4>
                    <div class="code-block">
                        <div class="code-header">
                            <span class="code-language">python</span>
                            <button class="copy-btn">å¤åˆ¶</button>
                        </div>
                        <pre><code class="language-python">from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.chat_history import InMemoryChatMessageHistory

# åˆ›å»ºåŸºç¡€é“¾
prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹"),
    ("placeholder", "{history}"),
    ("user", "{input}")
])

llm = ChatOpenAI(model="gpt-4o")
chain = prompt | llm

# åˆ›å»ºå†å²å­˜å‚¨
store = {}

def get_session_history(session_id: str):
    if session_id not in store:
        store[session_id] = InMemoryChatMessageHistory()
    return store[session_id]

# åŒ…è£…é“¾
with_history = RunnableWithMessageHistory(
    runnable=chain,
    get_session_history=get_session_history,
    input_messages_key="input",
    history_messages_key="history"
)

# ä½¿ç”¨ï¼ˆé€šè¿‡ config ä¼ é€’ session_idï¼‰
result = with_history.invoke(
    {"input": "ä½ å¥½ï¼"},
    config={"configurable": {"session_id": "user_123"}}
)

# ç¬¬äºŒè½®å¯¹è¯ï¼ˆä¼šåŒ…å«å†å²ï¼‰
result = with_history.invoke(
    {"input": "æˆ‘åˆšæ‰é—®äº†ä»€ä¹ˆï¼Ÿ"},
    config={"configurable": {"session_id": "user_123"}}
)</code></pre>
                    </div>
                </div>

                <h2 id="examples">ä½¿ç”¨ç¤ºä¾‹</h2>

                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">python</span>
                        <button class="copy-btn">å¤åˆ¶</button>
                        </div>
                        <pre><code class="language-python"># ========== ç¤ºä¾‹1: ä½¿ç”¨ ConversationBufferMemory ==========
from langchain.memory import ConversationBufferMemory
from langchain_openai import OpenAI
from langchain.chains import ConversationChain

llm = OpenAI(temperature=0)
memory = ConversationBufferMemory()

conversation = ConversationChain(
    llm=llm,
    memory=memory,
    verbose=True
)

# ç¬¬ä¸€è½®
response = conversation.predict(input="ä½ å¥½ï¼Œæˆ‘æ˜¯ Alice")
# ç¬¬äºŒè½®ï¼ˆåŒ…å«å†å²ï¼‰
response = conversation.predict(input="æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ")

# ========== ç¤ºä¾‹2: ä½¿ç”¨ RunnableWithMessageHistoryï¼ˆæ¨èï¼‰==========
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.chat_history import InMemoryChatMessageHistory

# å†å²å­˜å‚¨
chat_histories = {}

def get_history(session_id: str) -> BaseChatMessageHistory:
    if session_id not in chat_histories:
        chat_histories[session_id] = InMemoryChatMessageHistory()
    return chat_histories[session_id]

# åˆ›å»ºé“¾
prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹"),
    ("placeholder", "{history}"),
    ("user", "{input}")
])

chain = prompt | ChatOpenAI(model="gpt-4o")

# åŒ…è£…
with_history = RunnableWithMessageHistory(
    chain,
    get_history,
    input_messages_key="input",
    history_messages_key="history"
)

# å¤šç”¨æˆ·æ”¯æŒ
response1 = with_history.invoke(
    {"input": "ä½ å¥½ï¼Œæˆ‘æ˜¯ Bob"},
    config={"configurable": {"session_id": "user_1"}}
)

response2 = with_history.invoke(
    {"input": "ä½ å¥½ï¼Œæˆ‘æ˜¯ Carol"},
    config={"configurable": {"session_id": "user_2"}}
)

# æ¯ä¸ª session ç‹¬ç«‹
response3 = with_history.invoke(
    {"input": "æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ"},
    config={"configurable": {"session_id": "user_1"}}
)  # è¿”å› Bob</code></pre>
                </div>

                <h2>ç›¸å…³ API</h2>
                <ul>
                    <li><a href="stores.html">Stores API</a></li>
                    <li><a href="checkpointers.html">Checkpointers API</a></li>
                    <li><a href="../10-memory.html">æ•™ç¨‹ï¼šè®°å¿†ç®¡ç†</a></li>
                </ul>

                <div class="chapter-nav">
                    <a href="stores.html">â† Stores API</a>
                    <a href="checkpointers.html" class="next">Checkpointers API â†’</a>
                </div>
            </div>
        </main>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script src="../assets/js/main.js"></script>
</body>
</html>
