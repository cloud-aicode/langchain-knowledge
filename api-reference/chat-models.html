<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>èŠå¤©æ¨¡å‹ API - LangChain 1.0</title>
    <link rel="stylesheet" href="../assets/css/style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
</head>
<body class="chapter-api-chat-models">
    <button class="theme-toggle">ğŸŒ“</button>
    <button class="mobile-menu-btn" onclick="toggleSidebar()">â˜°</button>

    <div class="app-container">
        <nav class="sidebar">
            <div class="sidebar-header">
                <h1>LangChain 1.0</h1>
                <p style="color: rgba(255,255,255,0.6); font-size: 0.9rem; margin-top: 5px;">API å‚è€ƒ</p>
            </div>
            <div class="sidebar-nav"></div>
        </nav>

        <main class="main-content">
            <div class="content">
                <h1>èŠå¤©æ¨¡å‹ API</h1>
                <p class="subtitle">BaseChatModel ä¸èŠå¤©æ¨¡å‹å®ç°</p>

                <div class="api-nav">
                    <a href="#overview" class="api-nav-link">æ¦‚è¿°</a>
                    <a href="#classes" class="api-nav-link">æ ¸å¿ƒç±»</a>
                    <a href="#methods" class="api-nav-link">æ–¹æ³•</a>
                    <a href="#implementations" class="api-nav-link">å®ç°ç±»</a>
                    <a href="#examples" class="api-nav-link">ç¤ºä¾‹</a>
                </div>

                <h2 id="overview">æ¦‚è¿°</h2>
                <p>èŠå¤©æ¨¡å‹ï¼ˆChat Modelsï¼‰æ˜¯ LangChain ä¸­æœ€å¸¸ç”¨çš„æ¨¡å‹ç±»å‹ï¼Œå®ƒä»¬ä½¿ç”¨æ¶ˆæ¯åˆ—è¡¨ä½œä¸ºè¾“å…¥å’Œè¾“å‡ºï¼Œæ”¯æŒå¤šè½®å¯¹è¯ã€‚</p>

                <pre class="mermaid">graph TD
                    A[BaseChatModel] --> B[ChatOpenAI]
                    A --> C[ChatAnthropic]
                    A --> D[ChatGoogleGenerativeAI]
                    A --> E[AzureChatOpenAI]
                    A --> F[ChatBedrock]

                    B --> G[æ¨¡å‹æä¾›å•†]
                    C --> G
                    D --> G
                    E --> G
                    F --> G

                    style A fill:#e1f5fe
                    style G fill:#c8e6c9</code></pre>

                <h2 id="classes">æ ¸å¿ƒç±»</h2>

                <div class="api-section" id="basechatmodel">
                    <h3 class="api-title">BaseChatModel</h3>
                    <p class="api-description">æ‰€æœ‰èŠå¤©æ¨¡å‹çš„æŠ½è±¡åŸºç±»ã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">class BaseChatModel(BaseLanguageModel[List[BaseMessage], BaseMessage]):
    """èŠå¤©æ¨¡å‹åŸºç±»"""

    @property
    @abstractmethod
    def _llm_type(self) -> str:
        """è¿”å›æ¨¡å‹ç±»å‹"""

    @abstractmethod
    def _generate(
        self,
        messages: List[BaseMessage],
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
        **kwargs: Any,
    ) -> ChatResult:
        """ç”Ÿæˆå“åº”çš„æ ¸å¿ƒæ–¹æ³•"""

    def bind_tools(
        self,
        tools: Sequence[Union[StructuredTool, dict]],
        **kwargs: Any,
    ) -> Runnable[LanguageModelInput, BaseMessage]:
        """ç»‘å®šå·¥å…·åˆ°æ¨¡å‹"""

    def with_structured_output(
        self,
        schema: Union[Dict, Type[BaseModel]],
        *,
        method: Literal["tool_calling", "function_calling"] = "tool_calling",
        **kwargs: Any,
    ) -> Runnable[LanguageModelInput, Union[Dict, BaseModel]]:
        """é…ç½®ç»“æ„åŒ–è¾“å‡º"""</code></pre>
                    </div>

                    <h4>æ ¸å¿ƒå±æ€§</h4>
                    <table class="api-table">
                        <tr>
                            <th>å±æ€§</th>
                            <th>ç±»å‹</th>
                            <th>è¯´æ˜</th>
                        </tr>
                        <tr>
                            <td>bind_tools</td>
                            <td>method</td>
                            <td>ç»‘å®šå·¥å…·åˆ°æ¨¡å‹</td>
                        </tr>
                        <tr>
                            <td>with_structured_output</td>
                            <td>method</td>
                            <td>é…ç½®ç»“æ„åŒ–è¾“å‡º</td>
                        </tr>
                        <tr>
                            <td>with_retry</td>
                            <td>method</td>
                            <td>æ·»åŠ é‡è¯•é€»è¾‘</td>
                        </tr>
                    </table>
                </div>

                <h2 id="methods">æ ¸å¿ƒæ–¹æ³•</h2>

                <div class="api-section">
                    <h3 class="api-title">invoke</h3>
                    <p class="api-description">è°ƒç”¨èŠå¤©æ¨¡å‹ã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">def invoke(
    self,
    input: List[BaseMessage],
    config: Optional[RunnableConfig] = None,
    stop: Optional[List[str]] = None,
    **kwargs: Any,
) -> BaseMessage:
    """
    è°ƒç”¨èŠå¤©æ¨¡å‹

    Args:
        input: æ¶ˆæ¯åˆ—è¡¨
        config: è¿è¡Œé…ç½®
        stop: åœæ­¢è¯
        **kwargs: é¢å¤–å‚æ•°

    Returns:
        AIMessage å“åº”
    """</code></pre>
                    </div>

                    <h4>å‚æ•°è¯´æ˜</h4>
                    <table class="api-table">
                        <tr>
                            <th>å‚æ•°</th>
                            <th>ç±»å‹</th>
                            <th>è¯´æ˜</th>
                        </tr>
                        <tr>
                            <td>input</td>
                            <td>List[BaseMessage]</td>
                            <td>æ¶ˆæ¯åˆ—è¡¨ï¼ˆHumanMessage, SystemMessage, AIMessageï¼‰</td>
                        </tr>
                        <tr>
                            <td>config</td>
                            <td>RunnableConfig</td>
                            <td>è¿è¡Œé…ç½®ï¼ˆcallbacks, metadata, tagsï¼‰</td>
                        </tr>
                        <tr>
                            <td>stop</td>
                            <td>List[str]</td>
                            <td>åœæ­¢è¯åˆ—è¡¨</td>
                        </tr>
                        <tr>
                            <td>**kwargs</td>
                            <td>Any</td>
                            <td>æ¨¡å‹ç‰¹å®šå‚æ•°ï¼ˆtemperature, max_tokens ç­‰ï¼‰</td>
                        </tr>
                    </table>
                </div>

                <div class="api-section">
                    <h3 class="api-title">stream</h3>
                    <p class="api-description">æµå¼è°ƒç”¨èŠå¤©æ¨¡å‹ã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">def stream(
    self,
    input: List[BaseMessage],
    config: Optional[RunnableConfig] = None,
    stop: Optional[List[str]] = None,
    **kwargs: Any,
) -> Iterator[BaseMessageChunk]:
    """
    æµå¼è°ƒç”¨

    Yields:
        AIMessageChunk è¿­ä»£å™¨
    """</code></pre>
                    </div>
                </div>

                <div class="api-section">
                    <h3 class="api-title">bind_tools</h3>
                    <p class="api-description">ç»‘å®šå·¥å…·åˆ°æ¨¡å‹ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿè°ƒç”¨å·¥å…·ã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">def bind_tools(
    self,
    tools: Sequence[Union[StructuredTool, dict]],
    *,
    tool_choice: Optional[Union[dict, str, Literal["auto", "none", "required"]]] = None,
    **kwargs: Any,
) -> Runnable[List[BaseMessage], BaseMessage]:
    """
    ç»‘å®šå·¥å…·

    Args:
        tools: å·¥å…·åˆ—è¡¨
        tool_choice: å·¥å…·é€‰æ‹©ç­–ç•¥
            - "auto": æ¨¡å‹å†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·
            - "none": ä¸è°ƒç”¨å·¥å…·
            - "required": å¿…é¡»è°ƒç”¨å·¥å…·
            - dict/str: æŒ‡å®šç‰¹å®šå·¥å…·
        **kwargs: é¢å¤–å‚æ•°

    Returns:
        ç»‘å®šå·¥å…·åçš„ Runnable
    """</code></pre>
                    </div>
                </div>

                <div class="api-section">
                    <h3 class="api-title">with_structured_output</h3>
                    <p class="api-description">é…ç½®æ¨¡å‹è¾“å‡ºç»“æ„åŒ–æ•°æ®ã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">def with_structured_output(
    self,
    schema: Union[Dict, Type[BaseModel]],
    *,
    method: Literal["tool_calling", "function_calling"] = "tool_calling",
    **kwargs: Any,
) -> Runnable[List[BaseMessage], Union[Dict, BaseModel]]:
    """
    é…ç½®ç»“æ„åŒ–è¾“å‡º

    Args:
        schema: è¾“å‡ºç»“æ„ï¼ˆPydantic æ¨¡å‹æˆ–å­—å…¸ï¼‰
        method: æ–¹æ³•ç±»å‹
            - "tool_calling": ä½¿ç”¨å·¥å…·è°ƒç”¨
            - "function_calling": ä½¿ç”¨å‡½æ•°è°ƒç”¨
        **kwargs: é¢å¤–å‚æ•°

    Returns:
        è¿”å›ç»“æ„åŒ–æ•°æ®çš„ Runnable
    """</code></pre>
                    </div>

                    <h4>ç¤ºä¾‹</h4>
                    <div class="code-block">
                        <div class="code-header">
                            <span class="code-language">python</span>
                            <button class="copy-btn">å¤åˆ¶</button>
                        </div>
                        <pre><code class="language-python">from pydantic import BaseModel
from langchain_openai import ChatOpenAI

class Response(BaseModel):
    answer: str
    confidence: float

llm = ChatOpenAI(model="gpt-4o")
structured_llm = llm.with_structured_output(Response)

result = structured_llm.invoke([
    ("system", "ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹"),
    ("user", "å·´é»æ˜¯æ³•å›½çš„é¦–éƒ½å—ï¼Ÿ")
])
# result: Response(answer="æ˜¯çš„ï¼Œå·´é»æ˜¯æ³•å›½çš„é¦–éƒ½", confidence=0.95)</code></pre>
                    </div>
                </div>

                <div class="api-section">
                    <h3 class="api-title">with_retry</h3>
                    <p class="api-description">æ·»åŠ è‡ªåŠ¨é‡è¯•é€»è¾‘ã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">def with_retry(
    self,
    *,
    retry_if_exception_type: Tuple[Type[BaseException], ...] = (Exception,),
    max_retries: int = 3,
    wait_exponential_multiplier: float = 1.0,
    wait_exponential_max: float = 10.0,
) -> Runnable[LanguageModelInput, LanguageModelOutput]:
    """
    æ·»åŠ é‡è¯•

    Args:
        retry_if_exception_type: éœ€è¦é‡è¯•çš„å¼‚å¸¸ç±»å‹
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        wait_exponential_multiplier: æŒ‡æ•°é€€é¿ä¹˜æ•°
        wait_exponential_max: æœ€å¤§ç­‰å¾…æ—¶é—´

    Returns:
        å¸¦é‡è¯•çš„ Runnable
    """</code></pre>
                    </div>
                </div>

                <h2 id="implementations">å®ç°ç±»</h2>

                <div class="api-section" id="chatopenai">
                    <h3 class="api-title">ChatOpenAI</h3>
                    <p class="api-description">OpenAI èŠå¤©æ¨¡å‹å®ç°ã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    model: str = "gpt-4o",
    temperature: float = 0.7,
    max_tokens: Optional[int] = None,
    api_key: Optional[str] = None,
    base_url: Optional[str] = None,
    organization: Optional[str] = None,
    timeout: Optional[float] = None,
    max_retries: int = 2,
    streaming: bool = False,
    n: int = 1,
    top_p: float = 1.0,
    presence_penalty: float = 0.0,
    frequency_penalty: float = 0.0,
)</code></pre>
                    </div>

                    <h4>å‚æ•°è¯´æ˜</h4>
                    <table class="api-table">
                        <tr>
                            <th>å‚æ•°</th>
                            <th>ç±»å‹</th>
                            <th>é»˜è®¤å€¼</th>
                            <th>è¯´æ˜</th>
                        </tr>
                        <tr>
                            <td>model</td>
                            <td>str</td>
                            <td>gpt-4o</td>
                            <td>æ¨¡å‹åç§°</td>
                        </tr>
                        <tr>
                            <td>temperature</td>
                            <td>float</td>
                            <td>0.7</td>
                            <td>é‡‡æ ·æ¸©åº¦ (0-2)</td>
                        </tr>
                        <tr>
                            <td>max_tokens</td>
                            <td>int | None</td>
                            <td>None</td>
                            <td>æœ€å¤§ç”Ÿæˆ token æ•°</td>
                        </tr>
                        <tr>
                            <td>api_key</td>
                            <td>str | None</td>
                            <td>None</td>
                            <td>API å¯†é’¥</td>
                        </tr>
                        <tr>
                            <td>base_url</td>
                            <td>str | None</td>
                            <td>None</td>
                            <td>API åŸºç¡€ URL</td>
                        </tr>
                        <tr>
                            <td>timeout</td>
                            <td>float | None</td>
                            <td>None</td>
                            <td>è¯·æ±‚è¶…æ—¶ï¼ˆç§’ï¼‰</td>
                        </tr>
                        <tr>
                            <td>max_retries</td>
                            <td>int</td>
                            <td>2</td>
                            <td>æœ€å¤§é‡è¯•æ¬¡æ•°</td>
                        </tr>
                        <tr>
                            <td>streaming</td>
                            <td>bool</td>
                            <td>False</td>
                            <td>æ˜¯å¦å¯ç”¨æµå¼</td>
                        </tr>
                        <tr>
                            <td>n</td>
                            <td>int</td>
                            <td>1</td>
                            <td>ç”Ÿæˆå€™é€‰æ•°</td>
                        </tr>
                        <tr>
                            <td>top_p</td>
                            <td>float</td>
                            <td>1.0</td>
                            <td>æ ¸é‡‡æ ·å‚æ•°</td>
                        </tr>
                        <tr>
                            <td>presence_penalty</td>
                            <td>float</td>
                            <td>0.0</td>
                            <td>å­˜åœ¨æƒ©ç½š (-2 åˆ° 2)</td>
                        </tr>
                        <tr>
                            <td>frequency_penalty</td>
                            <td>float</td>
                            <td>0.0</td>
                            <td>é¢‘ç‡æƒ©ç½š (-2 åˆ° 2)</td>
                        </tr>
                    </table>
                </div>

                <div class="api-section" id="chatanthropic">
                    <h3 class="api-title">ChatAnthropic</h3>
                    <p class="api-description">Anthropic Claude èŠå¤©æ¨¡å‹å®ç°ã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">from langchain_anthropic import ChatAnthropic

llm = ChatAnthropic(
    model: str = "claude-3-5-sonnet-20241022",
    temperature: float = 0.7,
    max_tokens: int = 1024,
    api_key: Optional[str] = None,
    timeout: Optional[float] = None,
    max_retries: int = 2,
    top_k: Optional[int] = None,
    top_p: Optional[float] = None,
    streaming: bool = False,
)</code></pre>
                    </div>

                    <h4>Claude æ¨¡å‹</h4>
                    <ul>
                        <li>claude-3-5-sonnet-20241022 - æœ€æ–° Sonnet</li>
                        <li>claude-3-5-sonnet-20240620 - Sonnet 3.5</li>
                        <li>claude-3-opus-20240229 - Opus 3</li>
                        <li>claude-3-sonnet-20240229 - Sonnet 3</li>
                        <li>claude-3-haiku-20240307 - Haiku 3</li>
                    </ul>
                </div>

                <div class="api-section">
                    <h3 class="api-title">ChatGoogleGenerativeAI</h3>
                    <p class="api-description">Google Gemini èŠå¤©æ¨¡å‹å®ç°ã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">from langchain_google_genai import ChatGoogleGenerativeAI

llm = ChatGoogleGenerativeAI(
    model: str = "gemini-1.5-pro",
    temperature: float = 0.7,
    max_tokens: Optional[int] = None,
    api_key: Optional[str] = None,
    top_k: Optional[int] = None,
    top_p: Optional[float] = None,
)</code></pre>
                    </div>

                    <h4>Gemini æ¨¡å‹</h4>
                    <ul>
                        <li>gemini-1.5-pro - Gemini 1.5 Pro</li>
                        <li>gemini-1.5-flash - Gemini 1.5 Flash</li>
                        <li>gemini-pro - Gemini Pro</li>
                    </ul>
                </div>

                <div class="api-section">
                    <h3 class="api-title">AzureChatOpenAI</h3>
                    <p class="api-description">Azure OpenAI èŠå¤©æ¨¡å‹å®ç°ã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">from langchain_openai import AzureChatOpenAI

llm = AzureChatOpenAI(
    azure_deployment: str,
    openai_api_version: str,
    azure_endpoint: str,
    api_key: Optional[str] = None,
    azure_ad_token: Optional[str] = None,
    temperature: float = 0.7,
    max_tokens: Optional[int] = None,
)</code></pre>
                    </div>
                </div>

                <div class="api-section">
                    <h3 class="api-title">ChatBedrock</h3>
                    <p class="api-description">AWS Bedrock èŠå¤©æ¨¡å‹å®ç°ã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">from langchain_aws import ChatBedrock

llm = ChatBedrock(
    model_id: str = "anthropic.claude-3-5-sonnet-20241022-v2:0",
    region_name: str = "us-east-1",
    credentials_profile_name: Optional[str] = None,
    temperature: float = 0.7,
    max_tokens: int = 1024,
)</code></pre>
                    </div>
                </div>

                <h2 id="examples">ä½¿ç”¨ç¤ºä¾‹</h2>

                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">python</span>
                        <button class="copy-btn">å¤åˆ¶</button>
                    </div>
                    <pre><code class="language-python">from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

# åˆå§‹åŒ–
llm = ChatOpenAI(model="gpt-4o")

# åŸºç¡€è°ƒç”¨
response = llm.invoke([
    SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹"),
    HumanMessage(content="ä½ å¥½ï¼")
])
print(response.content)

# æµå¼è°ƒç”¨
for chunk in llm.stream([HumanMessage(content="è®²ä¸€ä¸ªæ•…äº‹")]):
    print(chunk.content, end="", flush=True)

# ç»‘å®šå·¥å…·
from langchain_core.tools import tool

@tool
def get_weather(location: str) -> str:
    """è·å–æŒ‡å®šåœ°ç‚¹çš„å¤©æ°”"""
    return f"{location} ä»Šå¤©æ˜¯æ™´å¤©ï¼Œæ¸©åº¦ 25Â°C"

llm_with_tools = llm.bind_tools([get_weather])
response = llm_with_tools.invoke([HumanMessage(content="åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")])

# ç»“æ„åŒ–è¾“å‡º
from pydantic import BaseModel

class Answer(BaseModel):
    summary: str
    confidence: float

structured_llm = llm.with_structured_output(Answer)
result = structured_llm.invoke([HumanMessage(content="æ€»ç»“ LangChain")])

# æ‰¹é‡å¤„ç†
messages = [
    [HumanMessage(content="ä»€ä¹ˆæ˜¯ Python?")],
    [HumanMessage(content="ä»€ä¹ˆæ˜¯ JavaScript?")],
    [HumanMessage(content="ä»€ä¹ˆæ˜¯ Rust?")]
]
responses = llm.batch(messages)

# å¼‚æ­¥è°ƒç”¨
import asyncio

async def async_chat():
    response = await llm.ainvoke([
        HumanMessage(content="ä½ å¥½")
    ])
    print(response.content)

    async for chunk in llm.astream([HumanMessage(content="ä»‹ç»è‡ªå·±")]):
        print(chunk.content, end="", flush=True)

asyncio.run(async_chat())</code></pre>
                </div>

                <h2>æ¶ˆæ¯ç±»å‹</h2>

                <div class="api-table">
                    <tr>
                        <th>ç±»å‹</th>
                        <th>è¯´æ˜</th>
                    </tr>
                    <tr>
                        <td>HumanMessage</td>
                        <td>ç”¨æˆ·æ¶ˆæ¯</td>
                    </tr>
                    <tr>
                        <td>SystemMessage</td>
                        <td>ç³»ç»Ÿæ¶ˆæ¯ï¼ˆè®¾ç½®è¡Œä¸ºï¼‰</td>
                    </tr>
                    <tr>
                        <td>AIMessage</td>
                        <td>AI æ¶ˆæ¯</td>
                    </tr>
                    <tr>
                        <td>ToolMessage</td>
                        <td>å·¥å…·è°ƒç”¨ç»“æœæ¶ˆæ¯</td>
                    </tr>
                    <tr>
                        <td>FunctionMessage</td>
                        <td>å‡½æ•°è°ƒç”¨ç»“æœæ¶ˆæ¯ï¼ˆå·²å¼ƒç”¨ï¼‰</td>
                    </tr>
                </div>

                <h2>ç›¸å…³ API</h2>
                <ul>
                    <li><a href="language-models.html">Language Models API</a></li>
                    <li><a href="prompts.html">Prompts API</a></li>
                    <li><a href="tools.html">Tools API</a></li>
                    <li><a href="../02-models.html">æ•™ç¨‹ï¼šè¯­è¨€æ¨¡å‹</a></li>
                </ul>

                <div class="chapter-nav">
                    <a href="language-models.html">â† Language Models API</a>
                    <a href="prompts.html" class="next">Prompts API â†’</a>
                </div>
            </div>
        </main>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script src="../assets/js/main.js"></script>
</body>
</html>
