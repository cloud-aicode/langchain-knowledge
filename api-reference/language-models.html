<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>è¯­è¨€æ¨¡å‹ API - LangChain 1.0</title>
    <link rel="stylesheet" href="../assets/css/style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
</head>
<body class="chapter-api-language-models">
    <button class="theme-toggle">ğŸŒ“</button>
    <button class="mobile-menu-btn" onclick="toggleSidebar()">â˜°</button>

    <div class="app-container">
        <nav class="sidebar">
            <div class="sidebar-header">
                <h1><a href="../index.html" style="color: white; text-decoration: none;">LangChain 1.0</a></h1>
                <p style="color: rgba(255,255,255,0.6); font-size: 0.9rem; margin-top: 5px;">API å‚è€ƒ</p>
            </div>
            <div class="sidebar-nav"></div>
        </nav>

        <main class="main-content">
            <div class="content">
                <h1>è¯­è¨€æ¨¡å‹ API</h1>
                <p class="subtitle">BaseLanguageModel ä¸ LLM ç»Ÿä¸€æ¥å£</p>

                <div class="api-nav">
                    <a href="#overview" class="api-nav-link">æ¦‚è¿°</a>
                    <a href="#classes" class="api-nav-link">æ ¸å¿ƒç±»</a>
                    <a href="#methods" class="api-nav-link">æ–¹æ³•</a>
                    <a href="#examples" class="api-nav-link">ç¤ºä¾‹</a>
                </div>

                <h2 id="overview">æ¦‚è¿°</h2>
                <p>LangChain çš„è¯­è¨€æ¨¡å‹æ¨¡å—æä¾›äº†ä¸å„ç§ LLM æä¾›å•†äº¤äº’çš„ç»Ÿä¸€æ¥å£ã€‚æ‰€æœ‰è¯­è¨€æ¨¡å‹éƒ½ç»§æ‰¿è‡ª <code>BaseLanguageModel</code> åŸºç±»ï¼Œæä¾›ä¸€è‡´çš„ APIã€‚</p>

                <pre class="mermaid">graph TD
                    A[BaseLanguageModel] --> B[LLM]
                    A --> C[BaseChatModel]

                    B --> D[OpenAI]
                    B --> E[Anthropic]
                    B --> F[Hugging Face]

                    C --> G[ChatOpenAI]
                    C --> H[ChatAnthropic]
                    C --> I[ChatGoogleGenerativeAI]

                    style A fill:#e1f5fe
                    style C fill:#c8e6c9</code></pre>

                <h2 id="classes">æ ¸å¿ƒç±»</h2>

                <div class="api-section" id="baselanguagemodel">
                    <h3 class="api-title">BaseLanguageModel</h3>
                    <p class="api-description">æ‰€æœ‰è¯­è¨€æ¨¡å‹çš„æŠ½è±¡åŸºç±»ï¼Œå®šä¹‰äº†ç»Ÿä¸€æ¥å£è§„èŒƒã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">class BaseLanguageModel(Serializable, Runnable[LanguageModelInput, LanguageModelOutput], Generic[LanguageModelInput, LanguageModelOutput]):
    """è¯­è¨€æ¨¡å‹åŸºç±»"""

    @property
    @abstractmethod
    def _llm_type(self) -> str:
        """è¿”å›æ¨¡å‹ç±»å‹æ ‡è¯†"""

    @abstractmethod
    def _generate(
        self,
        prompts: List[str],
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
        **kwargs: Any,
    ) -> LLMResult:
        """ç”Ÿæˆå“åº”çš„æ ¸å¿ƒæ–¹æ³•"""

    def generate_prompt(
        self,
        prompts: List[PromptValue],
        stop: Optional[List[str]] = None,
        callbacks: Callbacks = None,
        **kwargs: Any,
    ) -> LLMResult:
        """åŸºäº PromptValue ç”Ÿæˆå“åº”"""

    async def agenerate_prompt(
        self,
        prompts: List[PromptValue],
        stop: Optional[List[str]] = None,
        callbacks: Callbacks = None,
        **kwargs: Any,
    ) -> LLMResult:
        """å¼‚æ­¥ç”Ÿæˆå“åº”"""</code></pre>
                    </div>

                    <h4>å±æ€§</h4>
                    <table class="api-table">
                        <tr>
                            <th>å±æ€§</th>
                            <th>ç±»å‹</th>
                            <th>è¯´æ˜</th>
                        </tr>
                        <tr>
                            <td>_llm_type</td>
                            <td>str</td>
                            <td>æ¨¡å‹ç±»å‹æ ‡è¯†ï¼ˆå¦‚ "openai", "anthropic"ï¼‰</td>
                        </tr>
                    </table>

                    <h4>ç›¸å…³é“¾æ¥</h4>
                    <ul>
                        <li><a href="../02-models.html">æ•™ç¨‹ï¼šè¯­è¨€æ¨¡å‹</a></li>
                        <li><a href="chat-models.html">API: Chat Models</a></li>
                    </ul>
                </div>

                <div class="api-section">
                    <h3 class="api-title">LLM</h3>
                    <p class="api-description">çº¯æ–‡æœ¬è¯­è¨€æ¨¡å‹åŸºç±»ï¼Œå¤„ç†å­—ç¬¦ä¸²è¾“å…¥è¾“å‡ºã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">class LLM(BaseLanguageModel[str, str]):
    """çº¯æ–‡æœ¬è¯­è¨€æ¨¡å‹"""

    def __call__(self, text: str) -> str:
        """è°ƒç”¨æ¨¡å‹çš„ä¾¿æ·æ–¹æ³•"""

    def predict(self, text: str, **kwargs: Any) -> str:
        """é¢„æµ‹æ–‡æœ¬ï¼ˆå…¼å®¹æ–¹æ³•ï¼‰"""

    def predict_messages(
        self,
        messages: List[BaseMessage],
        **kwargs: Any
    ) -> BaseMessage:
        """é¢„æµ‹æ¶ˆæ¯å“åº”"""</code></pre>
                    </div>

                    <h4>å¸¸ç”¨å®ç°ç±»</h4>
                    <ul>
                        <li><code>OpenAI</code> - OpenAI GPT æ¨¡å‹</li>
                        <li><code>Anthropic</code> - Anthropic Claude æ¨¡å‹</li>
                        <li><code>HuggingFacePipeline</code> - Hugging Face æ¨¡å‹</li>
                    </ul>
                </div>

                <h2 id="methods">æ ¸å¿ƒæ–¹æ³•</h2>

                <div class="api-section">
                    <h3 class="api-title">invoke</h3>
                    <p class="api-description">åŒæ­¥è°ƒç”¨æ¨¡å‹ç”Ÿæˆå“åº”ã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">def invoke(
    self,
    input: LanguageModelInput,
    config: Optional[RunnableConfig] = None,
    stop: Optional[List[str]] = None,
    **kwargs: Any,
) -> LanguageModelOutput:
    """
    è°ƒç”¨æ¨¡å‹

    Args:
        input: è¾“å…¥æ–‡æœ¬æˆ–æ¶ˆæ¯åˆ—è¡¨
        config: è¿è¡Œé…ç½®ï¼ˆåŒ…å« callbacks, metadata ç­‰ï¼‰
        stop: åœæ­¢è¯åˆ—è¡¨
        **kwargs: é¢å¤–å‚æ•°

    Returns:
        æ¨¡å‹è¾“å‡ºï¼ˆå­—ç¬¦ä¸²æˆ– AIMessageï¼‰
    """</code></pre>
                    </div>

                    <h4>å‚æ•°è¯´æ˜</h4>
                    <table class="api-table">
                        <tr>
                            <th>å‚æ•°</th>
                            <th>ç±»å‹</th>
                            <th>è¯´æ˜</th>
                        </tr>
                        <tr>
                            <td>input</td>
                            <td>str | List[str]</td>
                            <td>è¾“å…¥æç¤ºæ–‡æœ¬</td>
                        </tr>
                        <tr>
                            <td>config</td>
                            <td>RunnableConfig | None</td>
                            <td>è¿è¡Œé…ç½®ï¼Œå¯åŒ…å« callbacksã€tagsã€metadata</td>
                        </tr>
                        <tr>
                            <td>stop</td>
                            <td>List[str] | None</td>
                            <td>åœæ­¢ç”Ÿæˆè¯åˆ—è¡¨</td>
                        </tr>
                        <tr>
                            <td>**kwargs</td>
                            <td>Any</td>
                            <td>æ¨¡å‹ç‰¹å®šå‚æ•°ï¼ˆå¦‚ temperature, max_tokensï¼‰</td>
                        </tr>
                    </table>

                    <h4>è¿”å›å€¼</h4>
                    <table class="api-table">
                        <tr>
                            <th>ç±»å‹</th>
                            <th>è¯´æ˜</th>
                        </tr>
                        <tr>
                            <td>str</td>
                            <td>ç”Ÿæˆçš„æ–‡æœ¬å“åº”</td>
                        </tr>
                    </table>
                </div>

                <div class="api-section">
                    <h3 class="api-title">stream</h3>
                    <p class="api-description">æµå¼è°ƒç”¨æ¨¡å‹ï¼Œé€ token è¿”å›ç»“æœã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">def stream(
    self,
    input: LanguageModelInput,
    config: Optional[RunnableConfig] = None,
    stop: Optional[List[str]] = None,
    **kwargs: Any,
) -> Iterator[LanguageModelOutput]:
    """
    æµå¼è°ƒç”¨æ¨¡å‹

    Args:
        input: è¾“å…¥æ–‡æœ¬
        config: è¿è¡Œé…ç½®
        stop: åœæ­¢è¯
        **kwargs: é¢å¤–å‚æ•°

    Yields:
        é€ token è¿”å›çš„è¾“å‡º
    """</code></pre>
                    </div>

                    <h4>è¿”å›å€¼</h4>
                    <table class="api-table">
                        <tr>
                            <th>ç±»å‹</th>
                            <th>è¯´æ˜</th>
                        </tr>
                        <tr>
                            <td>Iterator[str]</td>
                            <td>æ–‡æœ¬å—çš„è¿­ä»£å™¨</td>
                        </tr>
                    </table>
                </div>

                <div class="api-section">
                    <h3 class="api-title">batch</h3>
                    <p class="api-description">æ‰¹é‡å¤„ç†å¤šä¸ªè¾“å…¥ã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">def batch(
    self,
    inputs: List[LanguageModelInput],
    config: Optional[Union[RunnableConfig, List[RunnableConfig]]] = None,
    stop: Optional[List[str]] = None,
    **kwargs: Any,
) -> List[LanguageModelOutput]:
    """
    æ‰¹é‡è°ƒç”¨æ¨¡å‹

    Args:
        inputs: è¾“å…¥åˆ—è¡¨
        config: é…ç½®ï¼ˆå•ä¸ªæˆ–å¤šä¸ªï¼‰
        stop: åœæ­¢è¯
        **kwargs: é¢å¤–å‚æ•°

    Returns:
        è¾“å‡ºåˆ—è¡¨
    """</code></pre>
                    </div>
                </div>

                <div class="api-section">
                    <h3 class="api-title">ainvoke / astream / abatch</h3>
                    <p class="api-description">å¼‚æ­¥ç‰ˆæœ¬çš„è°ƒç”¨æ–¹æ³•ã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">async def ainvoke(
    self,
    input: LanguageModelInput,
    config: Optional[RunnableConfig] = None,
    stop: Optional[List[str]] = None,
    **kwargs: Any,
) -> LanguageModelOutput:
    """å¼‚æ­¥è°ƒç”¨æ¨¡å‹"""

async def astream(
    self,
    input: LanguageModelInput,
    config: Optional[RunnableConfig] = None,
    stop: Optional[List[str]] = None,
    **kwargs: Any,
) -> AsyncIterator[LanguageModelOutput]:
    """å¼‚æ­¥æµå¼è°ƒç”¨"""

async def abatch(
    self,
    inputs: List[LanguageModelInput],
    config: Optional[Union[RunnableConfig, List[RunnableConfig]]] = None,
    **kwargs: Any,
) -> List[LanguageModelOutput]:
    """å¼‚æ­¥æ‰¹é‡è°ƒç”¨"""</code></pre>
                    </div>
                </div>

                <div class="api-section">
                    <h3 class="api-title">bind</h3>
                    <p class="api-description">ç»‘å®šå‚æ•°åˆ°æ¨¡å‹ï¼Œåˆ›å»ºæ–°çš„å¯è¿è¡Œå¯¹è±¡ã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">def bind(
    self,
    **kwargs: Any,
) -> Runnable[LanguageModelInput, LanguageModelOutput]:
    """
    ç»‘å®šå‚æ•°

    Args:
        **kwargs: è¦ç»‘å®šçš„å‚æ•°ï¼ˆå¦‚ temperature=0.7ï¼‰

    Returns:
        ç»‘å®šå‚æ•°åçš„æ–° Runnable
    """</code></pre>
                    </div>

                    <h4>ç¤ºä¾‹</h4>
                    <div class="code-block">
                        <div class="code-header">
                            <span class="code-language">python</span>
                            <button class="copy-btn">å¤åˆ¶</button>
                        </div>
                        <pre><code class="language-python">from langchain_openai import OpenAI

llm = OpenAI(model="gpt-3.5-turbo-instruct")
cool_llm = llm.bind(temperature=0.3)
creative_llm = llm.bind(temperature=0.9)</code></pre>
                    </div>
                </div>

                <div class="api-section">
                    <h3 class="api-title">with_types</h3>
                    <p class="api-description">é…ç½®è¾“å…¥è¾“å‡ºç±»å‹ã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">def with_types(
    self,
    input_type: Optional[Type[LanguageModelInput]] = None,
    output_type: Optional[Type[LanguageModelOutput]] = None,
) -> Runnable[LanguageModelInput, LanguageModelOutput]:
    """
    é…ç½®ç±»å‹

    Args:
        input_type: è¾“å…¥ç±»å‹
        output_type: è¾“å‡ºç±»å‹

    Returns:
        é…ç½®ç±»å‹åçš„ Runnable
    """</code></pre>
                    </div>
                </div>

                <div class="api-section">
                    <h3 class="api-title">get_num_tokens</h3>
                    <p class="api-description">è®¡ç®—æ–‡æœ¬çš„ token æ•°é‡ã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">def get_num_tokens(self, text: str) -> int:
    """
    è®¡ç®— token æ•°é‡

    Args:
        text: è¦è®¡ç®—çš„æ–‡æœ¬

    Returns:
        token æ•°é‡
    """</code></pre>
                    </div>
                </div>

                <div class="api-section">
                    <h3 class="api-title">get_num_tokens_from_messages</h3>
                    <p class="api-description">è®¡ç®—æ¶ˆæ¯åˆ—è¡¨çš„ token æ•°é‡ã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">def get_num_tokens_from_messages(
    self,
    messages: List[BaseMessage],
) -> int:
    """
    è®¡ç®—æ¶ˆæ¯çš„ token æ•°é‡

    Args:
        messages: æ¶ˆæ¯åˆ—è¡¨

    Returns:
        token æ€»æ•°
    """</code></pre>
                    </div>
                </div>

                <h2 id="examples">ä½¿ç”¨ç¤ºä¾‹</h2>

                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">python</span>
                        <button class="copy-btn">å¤åˆ¶</button>
                    </div>
                    <pre><code class="language-python">from langchain_openai import OpenAI

# åˆå§‹åŒ–æ¨¡å‹
llm = OpenAI(
    model="gpt-3.5-turbo-instruct",
    temperature=0.7,
    max_tokens=1000,
    api_key="your-api-key"
)

# åŸºç¡€è°ƒç”¨
response = llm.invoke("è®²ä¸€ä¸ªå…³äº Python çš„æ•…äº‹")
print(response)

# æµå¼è°ƒç”¨
for chunk in llm.stream("ç”¨ä¸‰å¥è¯ä»‹ç»äººå·¥æ™ºèƒ½"):
    print(chunk, end="", flush=True)

# æ‰¹é‡è°ƒç”¨
responses = llm.batch([
    "ä»€ä¹ˆæ˜¯ Python?",
    "ä»€ä¹ˆæ˜¯ JavaScript?",
    "ä»€ä¹ˆæ˜¯ Rust?"
])

# ç»‘å®šå‚æ•°
cool_llm = llm.bind(temperature=0.1)
response = cool_llm.invoke("å†™ä¸€é¦–å…³äºç¼–ç¨‹çš„è¯—")

# å¸¦é…ç½®çš„è°ƒç”¨
response = llm.invoke(
    "å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—",
    config={
        "tags": ["creative", "poetry"],
        "metadata": {"user_id": "user_123"}
    }
)

# å¼‚æ­¥è°ƒç”¨
import asyncio

async def async_example():
    response = await llm.ainvoke("ä½ å¥½")
    print(response)

    async for chunk in llm.astream("ä»‹ç» LangChain"):
        print(chunk, end="", flush=True)

asyncio.run(async_example())</code></pre>
                </div>

                <h2>ç›¸å…³ API</h2>
                <ul>
                    <li><a href="chat-models.html">Chat Models API</a> - èŠå¤©æ¨¡å‹æ¥å£</li>
                    <li><a href="prompts.html">Prompts API</a> - æç¤ºæ¨¡æ¿</li>
                    <li><a href="runnables.html">Runnables API</a> - Runnable æ¥å£</li>
                </ul>

                <div class="chapter-nav">
                    <a href="index.html">â† API å‚è€ƒ</a>
                    <a href="chat-models.html" class="next">Chat Models API â†’</a>
                </div>
            </div>
        </main>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script src="../assets/js/main.js"></script>
</body>
</html>
