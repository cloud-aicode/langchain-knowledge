<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>è¯„ä¼°å™¨ API - LangChain 1.0</title>
    <link rel="stylesheet" href="../assets/css/style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
</head>
<body class="chapter-api-evaluators">
    <button class="theme-toggle">ğŸŒ“</button>
    <button class="mobile-menu-btn" onclick="toggleSidebar()">â˜°</button>

    <div class="app-container">
        <nav class="sidebar">
            <div class="sidebar-header">
                <h1><a href="../index.html" style="color: white; text-decoration: none;">LangChain 1.0</a></h1>
                <p style="color: rgba(255,255,255,0.6); font-size: 0.9rem; margin-top: 5px;">API å‚è€ƒ</p>
            </div>
            <div class="sidebar-nav"></div>
        </nav>

        <main class="main-content">
            <div class="content">
                <h1>è¯„ä¼°å™¨ API</h1>
                <p class="subtitle">è¯„ä¼°æ¡†æ¶ä¸è´¨é‡æŒ‡æ ‡</p>

                <div class="api-nav">
                    <a href="#overview" class="api-nav-link">æ¦‚è¿°</a>
                    <a href="#string" class="api-nav-link">å­—ç¬¦ä¸²è¯„ä¼°å™¨</a>
                    <a href="#load" class="api-nav-link">åŠ è½½è¯„ä¼°å™¨</a>
                    <a href="#examples" class="api-nav-link">ç¤ºä¾‹</a>
                </div>

                <h2 id="overview">æ¦‚è¿°</h2>
                <p>è¯„ä¼°å™¨ç”¨äºé‡åŒ– LLM åº”ç”¨çš„è¾“å‡ºè´¨é‡ï¼Œæ”¯æŒæ­£ç¡®æ€§ã€ç›¸å…³æ€§ã€è¿è´¯æ€§ç­‰å¤šç»´åº¦è¯„ä¼°ã€‚</p>

                <pre class="mermaid">graph TD
    A[Evaluators] --> B[StringEvaluator]
    A --> C[PairwiseStringEvaluator]
    A --> D[EmbeddingEvaluator]

    B --> E[å‡†ç¡®ç‡]
    B --> F[ç›¸å…³æ€§]

    C --> G[æˆå¯¹æ¯”è¾ƒ]

    D --> H[è¯­ä¹‰ç›¸ä¼¼åº¦]

    A --> I[load_evaluator]
    I --> J[labeled_criteria]
    I --> K[criteria]
    I --> L[labeled_pairwise_string]

    style A fill:#e1f5fe
    style I fill:#c8e6c9</code></pre>

                <h2 id="string">å­—ç¬¦ä¸²è¯„ä¼°å™¨</h2>

                <div class="api-section">
                    <h3 class="api-title">StringEvaluator</h3>
                    <p class="api-description">å­—ç¬¦ä¸²è¯„ä¼°å™¨åŸºç±»ã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">from langchain_core.evaluators import StringEvaluator

class StringEvaluator(ABC):
    """å­—ç¬¦ä¸²è¯„ä¼°å™¨åŸºç±»"""

    @property
    @abstractmethod
    def evaluation_name(self) -> str:
        """è¿”å›è¯„ä¼°å™¨åç§°"""

    @abstractmethod
    def evaluate_strings(
        self,
        *,
        prediction: str,
        reference: Optional[str] = None,
        input: Optional[str] = None,
        **kwargs: Any,
    ) -> dict:
        """
        è¯„ä¼°å­—ç¬¦ä¸²è¾“å‡º

        Args:
            prediction: æ¨¡å‹é¢„æµ‹è¾“å‡º
            reference: å‚è€ƒç­”æ¡ˆï¼ˆå¯é€‰ï¼‰
            input: è¾“å…¥ï¼ˆå¯é€‰ï¼‰
            **kwargs: é¢å¤–å‚æ•°

        Returns:
            è¯„ä¼°ç»“æœå­—å…¸ï¼Œé€šå¸¸åŒ…å«:
            - score: åˆ†æ•°ï¼ˆ0-1 æˆ–å…¶ä»–èŒƒå›´ï¼‰
            - reasoning: è¯„ä¼°ç†ç”±
            - å…¶ä»–è‡ªå®šä¹‰å­—æ®µ
        """

    async def aevaluate_strings(
        self,
        prediction: str,
        reference: Optional[str] = None,
        input: Optional[str] = None,
        **kwargs: Any,
    ) -> dict:
        """å¼‚æ­¥è¯„ä¼°"""

    def evaluate_strings_optimized(
        self,
        prediction: str,
        reference: Optional[str] = None,
        input: Optional[str] = None,
    ) -> dict:
        """ä¼˜åŒ–ç‰ˆè¯„ä¼°ï¼ˆæ‰¹é‡å¤„ç†ï¼‰"""</code></pre>
                    </div>
                </div>

                <div class="api-section">
                    <h3 class="api-title">PairwiseStringEvaluator</h3>
                    <p class="api-description">æˆå¯¹æ¯”è¾ƒè¯„ä¼°å™¨ã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">from langchain_core.evaluators import PairwiseStringEvaluator

class PairwiseStringEvaluator(ABC):
    """æˆå¯¹å­—ç¬¦ä¸²è¯„ä¼°å™¨"""

    @abstractmethod
    def evaluate_string_pairs(
        self,
        *,
        prediction: str,
        prediction_b: str,
        reference: Optional[str] = None,
        input: Optional[str] = None,
        **kwargs: Any,
    ) -> dict:
        """
        è¯„ä¼°ä¸¤ä¸ªè¾“å‡º

        Args:
            prediction: è¾“å‡º A
            prediction_b: è¾“å‡º B
            reference: å‚è€ƒç­”æ¡ˆï¼ˆå¯é€‰ï¼‰
            input: è¾“å…¥ï¼ˆå¯é€‰ï¼‰

        Returns:
            è¯„ä¼°ç»“æœ:
            - score: 0 (Aæ›´å¥½), 1 (Bæ›´å¥½), æˆ– None (å¹³å±€)
            - reasoning: è¯„ä¼°ç†ç”±
        """</code></pre>
                    </div>
                </div>

                <h2 id="load">åŠ è½½è¯„ä¼°å™¨</h2>

                <div class="api-section">
                    <h3 class="api-title">load_evaluator</h3>
                    <p class="api-description">åŠ è½½å†…ç½®è¯„ä¼°å™¨ã€‚</p>

                    <div class="api-signature">
                        <pre><code class="language-python">from langchain_core.evaluators import load_evaluator

def load_evaluator(
    evaluator: Union[
        EvaluatorsKeys,
        str,
    ],
    *,
    llm: Optional[BaseLanguageModel] = None,
    client: Optional[Client] = None,
    **kwargs: Any,
) -> Union[StringEvaluator, PairwiseStringEvaluator]:
    """
    åŠ è½½è¯„ä¼°å™¨

    Args:
        evaluator: è¯„ä¼°å™¨æ ‡è¯†
            - "criteria": è‡ªå®šä¹‰æ ‡å‡†è¯„ä¼°
            - "labeled_criteria": å¸¦æ ‡ç­¾çš„æ ‡å‡†è¯„ä¼°
            - "labeled_pairwise_string": æˆå¯¹æ¯”è¾ƒè¯„ä¼°
            - "embedding_distance": åµŒå…¥è·ç¦»è¯„ä¼°
            - "string_distance": å­—ç¬¦ä¸²è·ç¦»è¯„ä¼°
        llm: ç”¨äºè¯„ä¼°çš„ LLM
        client: LangSmith å®¢æˆ·ç«¯
        **kwargs: é¢å¤–å‚æ•°

    Returns:
        è¯„ä¼°å™¨å®ä¾‹
    """</code></pre>
                    </div>

                    <h4>å¯ç”¨è¯„ä¼°å™¨</h4>
                    <table class="api-table">
                        <tr>
                            <th>evaluator</th>
                            <th>è¯´æ˜</th>
                        </tr>
                        <tr>
                            <td>criteria</td>
                            <td>è‡ªå®šä¹‰æ ‡å‡†</td>
                        </tr>
                        <tr>
                            <td>labeled_criteria</td>
                            <td>å¸¦æ ‡ç­¾çš„æ ‡å‡†</td>
                        </tr>
                        <tr>
                            <td>labeled_pairwise_string</td>
                            <td>æˆå¯¹æ¯”è¾ƒ</td>
                        </tr>
                        <tr>
                            <td>embedding_distance</td>
                            <td>åµŒå…¥è·ç¦»</td>
                        </tr>
                        <tr>
                            <td>string_distance</td>
                            <td>å­—ç¬¦ä¸²è·ç¦»</td>
                        </tr>
                        <tr>
                            <td>qa</td>
                            <td>QA è¯„ä¼°</td>
                        </tr>
                        <tr>
                            <td>cot_qa</td>
                            <td>æ€ç»´é“¾ QA</td>
                        </tr>
                    </table>

                    <h4>ä½¿ç”¨ç¤ºä¾‹</h4>
                    <div class="code-block">
                        <div class="code-header">
                            <span class="code-language">python</span>
                            <button class="copy-btn">å¤åˆ¶</button>
                        </div>
                        <pre><code class="language-python">from langchain_core.evaluators import load_evaluator
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-4o", temperature=0)

# åŠ è½½æ ‡å‡†è¯„ä¼°å™¨
evaluator = load_evaluator(
    "labeled_criteria",
    criteria="correctness",
    llm=llm
)

result = evaluator.evaluate_strings(
    prediction="å·´é»æ˜¯æ³•å›½çš„é¦–éƒ½",
    reference="å·´é»æ˜¯æ³•å›½çš„é¦–éƒ½",
    input="æ³•å›½çš„é¦–éƒ½æ˜¯å“ªé‡Œï¼Ÿ"
)

print(f"åˆ†æ•°: {result['score']}")
print(f"ç†ç”±: {result['reasoning']}")</code></pre>
                    </div>
                </div>

                <div class="api-section">
                    <h3 class="api-title">è‡ªå®šä¹‰æ ‡å‡†è¯„ä¼°</h3>

                    <div class="api-signature">
                        <pre><code class="language-python">from langchain_core.evaluators import load_evaluator

# è‡ªå®šä¹‰æ ‡å‡†
custom_criteria = {
    "helpfulness": "è¾“å‡ºæ˜¯å¦å¯¹ç”¨æˆ·æœ‰å¸®åŠ©ï¼Ÿ",
    "clarity": "è¾“å‡ºæ˜¯å¦æ¸…æ™°æ˜äº†ï¼Ÿ",
    "accuracy": "è¾“å‡ºæ˜¯å¦å‡†ç¡®æ— è¯¯ï¼Ÿ",
    "relevance": "è¾“å‡ºæ˜¯å¦ä¸è¾“å…¥ç›¸å…³ï¼Ÿ"
}

evaluator = load_evaluator(
    "criteria",
    criteria=custom_criteria,
    llm=ChatOpenAI(model="gpt-4o")
)

result = evaluator.evaluate_strings(
    prediction="Python æ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€...",
    input="ä»€ä¹ˆæ˜¯ Pythonï¼Ÿ"
)</code></pre>
                    </div>
                </div>

                <div class="api-section">
                    <h3 class="api-title">æˆå¯¹æ¯”è¾ƒè¯„ä¼°</h3>

                    <div class="api-signature">
                        <pre><code class="language-python">from langchain_core.evaluators import load_evaluator

evaluator = load_evaluator(
    "labeled_pairwise_string",
    criteria="helpfulness",
    llm=ChatOpenAI(model="gpt-4o")
)

result = evaluator.evaluate_string_pairs(
    prediction="Python æ˜¯ä¸€ç§è¯­è¨€",
    prediction_b="Python æ˜¯ä¸€ç§ç”± Guido van Rossum åˆ›å»ºçš„é«˜çº§ç¼–ç¨‹è¯­è¨€",
    input="Python æ˜¯ä»€ä¹ˆï¼Ÿ",
    reference="Python æ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€"
)

print(f"èƒœå‡º: {result['score']}")  # A æˆ– B
print(f"ç†ç”±: {result['reasoning']}")</code></pre>
                    </div>
                </div>

                <div class="api-section">
                    <h3 class="api-title">åµŒå…¥è·ç¦»è¯„ä¼°</h3>

                    <div class="api-signature">
                        <pre><code class="language-python">from langchain_core.evaluators import load_evaluator
from langchain_openai import OpenAIEmbeddings

evaluator = load_evaluator(
    "embedding_distance",
    distance_metric="cosine",  # cosine, euclidean, manhattan
    embeddings=OpenAIEmbeddings()
)

result = evaluator.evaluate_strings(
    prediction="ç›¸ä¼¼çš„å†…å®¹",
    reference="ç›¸ä¼¼çš„å†…å®¹"
)

print(f"è·ç¦»åˆ†æ•°: {result['score']}")  # è·ç¦»è¶Šå°åˆ†æ•°è¶Šé«˜</code></pre>
                    </div>
                </div>

                <h2 id="examples">ä½¿ç”¨ç¤ºä¾‹</h2>

                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">python</span>
                        <button class="copy-btn">å¤åˆ¶</button>
                    </div>
                    <pre><code class="language-python"># ========== ç¤ºä¾‹1: è‡ªå®šä¹‰è¯„ä¼°å™¨ ==========
from langchain_core.evaluators import StringEvaluator
from typing import Optional

class ExactMatchEvaluator(StringEvaluator):
    """ç²¾ç¡®åŒ¹é…è¯„ä¼°å™¨"""

    @property
    def evaluation_name(self) -> str:
        return "exact_match"

    def evaluate_strings(
        self,
        *,
        prediction: str,
        reference: Optional[str] = None,
        input: Optional[str] = None,
    ) -> dict:
        score = 1 if prediction.strip() == reference.strip() else 0
        return {
            "score": score,
            "reasoning": f"é¢„æµ‹: {prediction} | å‚è€ƒ: {reference}"
        }

evaluator = ExactMatchEvaluator()
result = evaluator.evaluate_strings(
    prediction="Hello World",
    reference="Hello World"
)
# {"score": 1, "reasoning": "..."}

# ========== ç¤ºä¾‹2: æ‰¹é‡è¯„ä¼° ==========
test_cases = [
    {"input": "2+2=?", "reference": "4"},
    {"input": "æ³•å›½é¦–éƒ½?", "reference": "å·´é»"},
    {"input": "Python?", "reference": "ç¼–ç¨‹è¯­è¨€"}
]

for case in test_cases:
    prediction = llm.invoke(case["input"])
    result = evaluator.evaluate_strings(
        prediction=prediction.content,
        reference=case["reference"],
        input=case["input"]
    )
    print(f"è¾“å…¥: {case['input']}, åˆ†æ•°: {result['score']}")

# ========== ç¤ºä¾‹3: è¯„ä¼°é“¾ ==========
from langchain_core.runnables import RunnableLambda
from langchain_core.prompts import ChatPromptTemplate

# åˆ›å»ºè¯„ä¼°é“¾
eval_prompt = ChatPromptTemplate.from_template("""
è¯„ä¼°ä»¥ä¸‹å›ç­”çš„è´¨é‡:

é—®é¢˜: {input}
å›ç­”: {prediction}

è¯·è¯„åˆ† (0-1): {grading_prompt}
""")

eval_chain = eval_prompt | llm | StrOutputParser()

# ========== ç¤ºä¾‹4: RAG è¯„ä¼° (RAGAS) ==========
from ragas import evaluate
from ragas.metrics import (
    faithfulness,
    answer_relevancy,
    context_recall,
    context_precision
)

test_data = {
    "question": ["ä»€ä¹ˆæ˜¯ LangChainï¼Ÿ"],
    "answer": ["LangChain æ˜¯ä¸€ä¸ªæ¡†æ¶"],
    "contexts": [["LangChain æ˜¯..."]],  # æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
    "ground_truth": ["LangChain æ˜¯ LLM åº”ç”¨æ¡†æ¶"]
}

result = evaluate(
    test_data,
    metrics=[faithfulness, answer_relevancy, context_recall, context_precision]
)

print(result.to_pandas())

# ========== ç¤ºä¾‹5: A/B æµ‹è¯•è¯„ä¼° ==========
evaluator = load_evaluator("labeled_pairwise_string", llm=llm)

# ä¸¤ä¸ªç‰ˆæœ¬
results_v1 = chain_v1.batch(inputs)
results_v2 = chain_v2.batch(inputs)

for i, (r1, r2) in enumerate(zip(results_v1, results_v2)):
    comparison = evaluator.evaluate_string_pairs(
        prediction=r1.content,
        prediction_b=r2.content,
        input=inputs[i]
    )
    print(f"è¾“å…¥ {i}: {comparison['score']} (Aæ›´å¥½=0, Bæ›´å¥½=1)")</code></pre>
                </div>

                <h2>ç›¸å…³ API</h2>
                <ul>
                    <li><a href="tracers.html">Tracers API</a></li>
                    <li><a href="../16-evaluation.html">æ•™ç¨‹ï¼šè¯„ä¼°æ¡†æ¶</a></li>
                </ul>

                <div class="chapter-nav">
                    <a href="tracers.html">â† Tracers API</a>
                    <a href="langgraph.html" class="next">LangGraph API â†’</a>
                </div>
            </div>
        </main>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script src="../assets/js/main.js"></script>
</body>
</html>
